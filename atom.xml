<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>抬头看路,低头干活</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://hanwen.me/"/>
  <updated>2019-08-13T12:37:41.532Z</updated>
  <id>http://hanwen.me/</id>
  
  <author>
    <name>Hanwen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《战胜华尔街》读书散想</title>
    <link href="http://hanwen.me/2019/08/13/readbook/"/>
    <id>http://hanwen.me/2019/08/13/readbook/</id>
    <published>2019-08-13T12:32:30.000Z</published>
    <updated>2019-08-13T12:37:41.532Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/ben-yousself.jpg" alt="Alt text"><br>空闲时间把《战胜华尔街》一点一点的读完，一开始读这本书的时候，确实感觉到没什么意思，就是觉得是一个人在以故事的方式讲述自己的投资经历。这些经历还是发生在几十年以前的故事以及公司，读起来总感觉不像读书的样子，欠缺一些说不出来的感觉。</p><p>但是随着时间推移，等读到后面一部分的时候，发现其实还是有内容的，后面总结的一些话，读起来让眼里一亮，给人的感觉就是这个话用在我大 A 股上面也是成立的。或许看到后面，再回想读前面的内容时，那种想法，想想有时候是自己知识欠缺导致的，并没有达到别人的那个水平，还总觉得别人写的内容，不那么实用。看书多少带有功利之心，导致不能更好的吸收，而读到后面的时候，发现有些话是能够深刻体会到的，想必这个是建立在自己的经历之上，才会发出原来这本书还是值得一读的。<br><a id="more"></a><br>读书万不可带着功利之心去读，但是读投资理财之类的书籍，又很难去抛开那种心理，带着一定程度的功利之心有时候也未必不可，因为只有心中到这目的去做某件事，可能成功的机会会更大，学习到的东西更多。</p><p>如果是拿读书当修心养性，那就把功利之心去除吧。</p><p>这本书里面给自己最有感触的是我们可以通过后视镜来观察到自己是走在康庄大道，还是走在泥路上。有的时候人在做事情时很容易就被蒙蔽了双眼，看不到前面的道路，一味的在不知道未来道路如何时，还在不停的向前开去，其实这个时候双眼已经不知道路是好走还是不好走。但这个时候我们可以通过回过头看看，或者通过后视镜来看自己走在什么路上，看看自己走在康庄大道上，还是在泥路上。如果是在走在康庄大道上那么应该庆幸自己有好运气。如果发现走在泥路上，请及时去改成，去止损。</p><p>走在泥路上，就跟看 K 线图一样，看看买入后的点，是不是买在了一直在走下坡路的个股，把 K 线图拉长之后，可能就发现原来在一条下坡路上，并且这个下坡还未有改变的趋势，这个时候需要下定决心把这个错误改掉，不要在去相信所谓的超低反弹，总对自己说以后会好的，最后可能会发现这条下坡路一直下坡，直到退市。</p><p>另外一个最直接有用去排除企业的方法：公司，就像人一样，改名字有两个原因，要么是结婚，要么是希望公众把他们的失败忘记掉。</p><p>这个特么是真理，难道不是嘛，把人的心理摸的透透的，让人们忘记过去的伤，等忘记之后再来添新伤，只是伤害你的人变了一个名字而已，怎么能让同一个人伤自己两次。</p><p>市场上确实有不少喜欢捡烟蒂的，毕竟大家的心理在那里，都希望能够投机取巧，买那些被 ST 的个股，觉得要是经营改善或者公司运营变好，股价会回升的，这一些特么都是幻想，最好不要去拥有这种心理。买这些个股不外乎就是股价便宜，而散户正是缺钱的主，那一点钱拿来买便宜的，可以买到更多股，而不是去挑选好的股。</p><p>最后，也有一个比较好的选股：要把你想选择的股看成那种你想带回家给老妈看的女孩子。只有是真正做过分析，做过研究的，发现这个股是真好，想必会有这种想法，如果自己内心都没有这种想法，那最好还是不要去拥有它，因为你并不了解它，反而它会给你带来伤害。不想拥有的，做做短线玩玩可以，但是不要幻想去长期拥有。长期值得拥有的就是那些你想带回家的。</p><p>希望，以后能找到能够带回家给老妈看的女孩子。在市场中做一个合格的学生，始终保持着学习，不忘初心，方得始终。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/ben-yousself.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;空闲时间把《战胜华尔街》一点一点的读完，一开始读这本书的时候，确实感觉到没什么意思，就是觉得是一个人在以故事的方式讲述自己的投资经历。这些经历还是发生在几十年以前的故事以及公司，读起来总感觉不像读书的样子，欠缺一些说不出来的感觉。&lt;/p&gt;
&lt;p&gt;但是随着时间推移，等读到后面一部分的时候，发现其实还是有内容的，后面总结的一些话，读起来让眼里一亮，给人的感觉就是这个话用在我大 A 股上面也是成立的。或许看到后面，再回想读前面的内容时，那种想法，想想有时候是自己知识欠缺导致的，并没有达到别人的那个水平，还总觉得别人写的内容，不那么实用。看书多少带有功利之心，导致不能更好的吸收，而读到后面的时候，发现有些话是能够深刻体会到的，想必这个是建立在自己的经历之上，才会发出原来这本书还是值得一读的。&lt;br&gt;
    
    </summary>
    
    
      <category term="杂谈" scheme="http://hanwen.me/tags/%E6%9D%82%E8%B0%88/"/>
    
      <category term="读书" scheme="http://hanwen.me/tags/%E8%AF%BB%E4%B9%A6/"/>
    
      <category term="感悟" scheme="http://hanwen.me/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>如何创造财富</title>
    <link href="http://hanwen.me/2019/01/21/create-wealth/"/>
    <id>http://hanwen.me/2019/01/21/create-wealth/</id>
    <published>2019-01-21T06:54:27.000Z</published>
    <updated>2019-01-21T06:58:58.081Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/creat_wealth.jpg" alt="Alt text"><br>如何让自己创造更多的财富。</p><p>想要从底层挤出，需要我们不懈的努力，光是拼工作是不行的。需要有理财的观念，而不是只是靠工作来增加自己的收入。要想自由须先实现财务自由，自由==钱？这个等式应该在许多情况下成立。</p><p>那实现财务自由，需要经过一些必要的阶段。第一阶段就是要有现金流。第二阶段是增加自己的本金，积累更多的现金流。第三阶段是增加收入来源，这也是在提高第二阶段的本金。第四阶段是管理和控制资金，其中包括投资。第五阶段是投资回报（收益）。<br><a id="more"></a>  </p><p>现有的一些保守投资收益是比较低的，比如你把钱存到银行中，银行每年也就 3%—4% 的回报。而投资股票市场可能会有 20% 左右的回报，但是有风险。那么如果想要 1000% 的回报该怎么办，又不想承担大风险，那就是投资你自己。</p><p>你自己本身就是一项资产，而这项资产正是你的思想，也就是你的知识资产，这是每个人都有的，上帝很公平。但是光有这个是不行的，还需要有对使用知识创造财富的饥渴。</p><p>举个公司的例子，像谷歌、微软、耐克这些公司的收益，90% 都是来自于知识资产，而不是流水线。这是值得很多公司学习的。</p><p>而在信息化（互联网）的今天，如何能够获取更多的钱，需要你对信息敏感，可以通过观察信息，发现一些商机。比如有事件发生了，那么在不同的人看来有不同的想法，自媒体人想到的是如何利用事件获取更多的流量（阅读），微商看到的是如何利用事件来赚钱。所以相同的事情在不同的人看来是有不同的想法，就看你想干什么了。</p><p>还有一些人会利用信息差来赚钱，同样也是一项能力。信息差就是信息传播有快慢，早知道的可以赚晚知道的钱，就是这么容易。可能有人说，在互联网，自媒体这么发达的时代，还会有信息差？这样想就错了，在中国可能一条信息对于大多数都已经知道了，但是最起码有 1 亿人是不知道，这就是信息差。</p><p>说了这么多，还是回到怎样才能赚取更多的钱。一是需要有理财的观念，其实现在有很多人都没有理财的意识，觉得就那么一点钱，至于理财吗，千万不要有这种想法，理财不在于钱多钱少，而是一种思想意识，在 40 岁之前可能感觉不重要，但是 40 岁之后就会有很深的感触，这是前期的量变引起的质变，所以需要先把量积累到一定程度，才会发生一定的质变。培养投资理财意识可以多看一些投资理财之类的书籍，比如巴菲特，芒格，林奇等人所写的书籍，如果觉得这些看着闲累，可以去看《富爸爸穷爸爸》系列。</p><p>二是需要花大量时间来学习，既然想要财务自由。如果靠自己，需要你不断的努力，别人在花时间看电视、看综艺时，你需要去学习。如果可以继承那就是另外一种说法了，这里只说通过自己来实现，而不借助其它的。</p><p>而这些最好是在一线城市，一线城市是给那些想靠自己闯出一片天地最好的环境，凭的是实力，赚钱效应也快。 特别是互联网时代，给了很多人机会。</p><p>最后，你的工作收入并不能给你带来很多回报，这些只是生活中的一部分，想实现财务自由是你的思想而不是努力工作。努力工作获得的收入是有一定的限度，而利用自己的想法来赚钱，是没有限度的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/creat_wealth.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;如何让自己创造更多的财富。&lt;/p&gt;
&lt;p&gt;想要从底层挤出，需要我们不懈的努力，光是拼工作是不行的。需要有理财的观念，而不是只是靠工作来增加自己的收入。要想自由须先实现财务自由，自由==钱？这个等式应该在许多情况下成立。&lt;/p&gt;
&lt;p&gt;那实现财务自由，需要经过一些必要的阶段。第一阶段就是要有现金流。第二阶段是增加自己的本金，积累更多的现金流。第三阶段是增加收入来源，这也是在提高第二阶段的本金。第四阶段是管理和控制资金，其中包括投资。第五阶段是投资回报（收益）。&lt;br&gt;
    
    </summary>
    
    
      <category term="努力" scheme="http://hanwen.me/tags/%E5%8A%AA%E5%8A%9B/"/>
    
      <category term="财富" scheme="http://hanwen.me/tags/%E8%B4%A2%E5%AF%8C/"/>
    
      <category term="投资" scheme="http://hanwen.me/tags/%E6%8A%95%E8%B5%84/"/>
    
      <category term="理财" scheme="http://hanwen.me/tags/%E7%90%86%E8%B4%A2/"/>
    
      <category term="奋斗" scheme="http://hanwen.me/tags/%E5%A5%8B%E6%96%97/"/>
    
      <category term="有钱人" scheme="http://hanwen.me/tags/%E6%9C%89%E9%92%B1%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>2018小小总结</title>
    <link href="http://hanwen.me/2019/01/01/summary-2018/"/>
    <id>http://hanwen.me/2019/01/01/summary-2018/</id>
    <published>2019-01-01T09:23:27.000Z</published>
    <updated>2019-01-01T09:36:41.215Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/summary2018.jpg" alt="Alt text"><br>今天是 2018 年最后一个工作日了，希望大家都过的愉快。</p><h4 id="1-关于投资"><a href="#1-关于投资" class="headerlink" title="1. 关于投资"></a>1. 关于投资</h4><p>如果从股票交易日来说的话，昨天是 2018 年的最后一个交易日，这一年对投资者非常不善待。很多人在这一年的收益都是负的，连银行都没有跑赢。这才是真的市场吧，有牛市也就有漫长的熊市，未来一年内也会继续着这样的日子，要学会在煎熬的岁月度过，坚守自己的投资原则，相信未来的牛是存在的。<a id="more"></a>如果只是单纯的靠赌可能会吃大亏，做投资还是需要深入挖掘公司的价值才是真道理，而不是简简单单的看了 K 线，就匆忙下单。</p><p>这里给大家几点个人的建议，在看股票的时候，经常会参考股票趋势，一定不要跟趋势反着做，不然会亏大的。如果一只股，你通过看它的趋势是在向下走，而且是那么的明显，索然目前的价格已经比之前高价时候低了很多，但是也不要轻易去建仓，因为这趋势可能会继续向下走下去的概率比向上走的概率大的太多了，做投资有时候我们就是在做选择，选择概率大的那一半，才会有所收益。</p><p>看了一下，今年我是9月份开始建仓的，算了一下目前的收益是 -3.5%，作为初入市场，还是感觉有点不爽，毕竟雪花白银流失了。但是相比于大盘还是跑赢了很多，相信时间会见证一些的，如果还在继续跌的话，也有可能会继续加入定投，但绝不会去上杠杠。前提是会做好准备的，刚进入市场，就经历了这一段时间的熊，考验的真是人心，能够做到不受影响，那是值得尊敬的。怪不得巴菲特前辈说：别人贪婪，我恐惧。别人恐惧，我贪婪。这有一大部分都是在于人，人的行为不可不考虑。</p><p>今天在《助推》里面看到一个词：自由主义的和谐专制主义，说的还是满有道理的，有兴趣的朋友，可以看看。</p><h4 id="2-年轻的资本"><a href="#2-年轻的资本" class="headerlink" title="2. 年轻的资本"></a>2. 年轻的资本</h4><p>我们还很年轻，年轻是我们的资本，这个时候我们没有那么多的烦恼。不需要去想我该买哪一只股，孩子应该去什么样的学校，晚上应该吃什么。我们需要做的是去做有意义的事情，提升自己。在年轻的时候，应该多一些拼搏，多一些储备，这样到老了才不会后悔。</p><p>但是年轻的时光也不是给我们试错的，也请不要任意挥霍。年轻是我们最好的一段时光，这个时候我们有年轻的心态，健康的体魄，灵敏的思维，这是做事情最好的条件，请善待。</p><p>记得多读书，多学习，多看看外面的世界。</p><h4 id="3-用心做事"><a href="#3-用心做事" class="headerlink" title="3. 用心做事"></a>3. 用心做事</h4><p>这一年发生了很多事情，实在是感概呀。比如长生生物，还有最近的权健事件，都让人觉得悲哀，但是看到有人能站出来去揭发，非常敬佩这些敢于站出来的，让事情的本来面目显示出来，这个社会需要更多这样的人。</p><p>反观之，也有很多人在默默的做着有意义的事情，比如无码科技推出的全球临床实验和就诊助理小程序，可能大家都不知道这两款小程序，也希望大家永远都不会用到，但是大家一定都知道微信小程序里面的抽奖助手，抽奖助手就是他们家的。他们在做着有意义的事情，并且用心在做，是我的榜样。</p><p>以后自己有能力了，也会去做有意义的事情，用心去做，做一些有贡献的，向前辈们学习。最后需要的是要不断的提升自己，时刻准备着。</p><h4 id="最后，2019-年加油，冲鸭！！！！"><a href="#最后，2019-年加油，冲鸭！！！！" class="headerlink" title="最后，2019 年加油，冲鸭！！！！"></a>最后，2019 年加油，冲鸭！！！！</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/summary2018.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;今天是 2018 年最后一个工作日了，希望大家都过的愉快。&lt;/p&gt;
&lt;h4 id=&quot;1-关于投资&quot;&gt;&lt;a href=&quot;#1-关于投资&quot; class=&quot;headerlink&quot; title=&quot;1. 关于投资&quot;&gt;&lt;/a&gt;1. 关于投资&lt;/h4&gt;&lt;p&gt;如果从股票交易日来说的话，昨天是 2018 年的最后一个交易日，这一年对投资者非常不善待。很多人在这一年的收益都是负的，连银行都没有跑赢。这才是真的市场吧，有牛市也就有漫长的熊市，未来一年内也会继续着这样的日子，要学会在煎熬的岁月度过，坚守自己的投资原则，相信未来的牛是存在的。
    
    </summary>
    
    
      <category term="总结" scheme="http://hanwen.me/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="努力" scheme="http://hanwen.me/tags/%E5%8A%AA%E5%8A%9B/"/>
    
      <category term="未来" scheme="http://hanwen.me/tags/%E6%9C%AA%E6%9D%A5/"/>
    
      <category term="投资" scheme="http://hanwen.me/tags/%E6%8A%95%E8%B5%84/"/>
    
      <category term="读书" scheme="http://hanwen.me/tags/%E8%AF%BB%E4%B9%A6/"/>
    
      <category term="2018" scheme="http://hanwen.me/tags/2018/"/>
    
      <category term="年轻" scheme="http://hanwen.me/tags/%E5%B9%B4%E8%BD%BB/"/>
    
  </entry>
  
  <entry>
    <title>闲聊 | 学会理财</title>
    <link href="http://hanwen.me/2018/12/31/inverst-note/"/>
    <id>http://hanwen.me/2018/12/31/inverst-note/</id>
    <published>2018-12-31T03:52:42.000Z</published>
    <updated>2018-12-31T04:00:22.114Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/inverstnote.jpeg" alt="Alt text"><br>今天我们来聊聊关于投资理财的话题，闲聊一些，说说自己最近的一些感受，投资理财理好了，可以实现一定的收益。理坏了，可能就会损失一部分本金，也有可能会一无所有。可以依据自己的性格来选择，如果不喜欢心跳的感觉，可以选择买余额宝。喜欢挑战的，可以选一些高风险的投资，比如股票、基金、债券、期货等。<br><a id="more"></a> </p><p>当下正是经历寒冬之际，我们还是以现金为主，不宜下水。接下来的一两年中，都要学会接受这漫漫的长途跋涉，这个时候非常适合努力充实自己，提高自己的能力，在机会来临的时候能够赶上，而不是坐以待毙。雷总说过，站在互联网的风口上，猪都能飞起来，那也要看你站的位置，而不是任何猪都能飞起来，要学会顺势而为，逆势努力，未来才不会亏待你自己。</p><p>今天距离 2019 年还有 8 天的时间，现在看来从现在看经济形式，很多投资的人，今年基本上是亏损的，完全没有跑赢指数，还不如别人把钱存银行的最赚。流行的一句话：2018 年最佳投资就是把钱存银行中。但是作为投资，我们不能只能看眼前利益，要把投资收益放到 3 到 5 年来看，或者更长时间来看，如果只是看短暂的收益，那无异于赌徒了。</p><p>巴菲特著名的话语：别人贪婪，我恐惧，别人恐惧，我贪婪。道出了投资的真谛。有些事情其实很简单，只不过我们把它们看的太复杂了，往往对最佳起到阻碍作用，当遇到想不开的事情时，可以放心手中的工作，走出去看看，或者冥想，从会有意外的收获。</p><p>如今的社会，遍地是充满着机遇，就看我们能不能抓住。在这个时势造英雄的时代，而不是英雄造时势的时代，需要我们努力变得优秀。如果把以前的英雄放到当下的社会，他们未必会有过去的那么大成就。做好自己，抓住当下的时势，期待着在一波的风口之上，你我都能飞起。</p><p>昨天去参加了雪球私募黄建平老师的见面会，很庆幸能够参加，并且获得了一本签名书。在现场见识了不少大佬，都是很有经历的前辈，见识了更多的投资人。渺小的自己，内心非常没有自信。还需要极大提高自己的能力，优秀的人之所以优秀是有原因的，相信他们也都曾经努力过、拼搏过。</p><p>现场分享了一些股票的知识和讨论了一些问题，分享过程中才感觉到自己目前学习的知识和经验，还差很远。做任何一件事，都需要花功夫去研究，而不是简简单单的通过看几条趋势线就可以了。挖掘出一家有价值的公司，是需要时间的。</p><p>投资过程中，不宜过于分散。过于分散并不会降低太多的风险，还有可能会减少一定的收益。这是一条建议。</p><p>投资虽然不是必须的，但是如果你想获取一定的收益，并且想实现一定的财务自由，对于工作的我们来说，这应该最可能实现的一条道路了，比买彩票强多了。</p><p>想开始接触投资理财的，可以从书籍开始，这也不需要自己花几个钱，买本书感受一些别人的理财观念是多么强烈，那时候可能就会激励你自己也想去理财了。并不是说钱少就不能理财，这是一种错误的说法，作为学生一样可以定自己的计划，来进行定投。这里推荐一本非常有金钱观念的书籍《小狗钱钱》，白话文写的，对没有接触过理财之类的非常适合。</p><p>希望，我们越来越好。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/inverstnote.jpeg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;今天我们来聊聊关于投资理财的话题，闲聊一些，说说自己最近的一些感受，投资理财理好了，可以实现一定的收益。理坏了，可能就会损失一部分本金，也有可能会一无所有。可以依据自己的性格来选择，如果不喜欢心跳的感觉，可以选择买余额宝。喜欢挑战的，可以选一些高风险的投资，比如股票、基金、债券、期货等。&lt;br&gt;
    
    </summary>
    
    
      <category term="投资" scheme="http://hanwen.me/tags/%E6%8A%95%E8%B5%84/"/>
    
      <category term="理财" scheme="http://hanwen.me/tags/%E7%90%86%E8%B4%A2/"/>
    
      <category term="闲聊" scheme="http://hanwen.me/tags/%E9%97%B2%E8%81%8A/"/>
    
      <category term="笔记" scheme="http://hanwen.me/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="成长" scheme="http://hanwen.me/tags/%E6%88%90%E9%95%BF/"/>
    
      <category term="收获" scheme="http://hanwen.me/tags/%E6%94%B6%E8%8E%B7/"/>
    
  </entry>
  
  <entry>
    <title>闲聊 | 读书</title>
    <link href="http://hanwen.me/2018/12/26/recommend-book/"/>
    <id>http://hanwen.me/2018/12/26/recommend-book/</id>
    <published>2018-12-26T12:19:44.000Z</published>
    <updated>2018-12-26T12:27:56.134Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/bookbackage.png" alt="Alt text"><br>记录一些读过的书籍，都颇有感触。</p><p>或许以前读书的境界还没够，还未达到一定的水准。最近每每看书都有很多感慨，读书能让你见识更多。作者把自己的亲身实践，通过文字的形式向我们展示，透过这些文字我们可以直接去借鉴。</p><p>《战后日本经济史》，这本书是讲日本是如何崛起的，其实我们现在的状况跟九几年的日本很相似，想想还未能为祖国做贡献，颇有无奈。<br><a id="more"></a><br>《不抱怨时间》《清单革命》，这两本书如何教你管理自己的时间，对于没有很强的自制力，非常适合，任务的完成总要有个轻重缓急，学会安排自己的时间，让自己过的更充实些。</p><p>《人类群星闪耀时》，讲述 13 个非常伟大的故事，在历史上总是有那么几个决定性的英雄人物，在任何时代都是存在的。成为英雄有时也就在那么一瞬间。</p><p> 《当下的力量》，讲述如何提高自己，文字是字字铿锵有力，里面有讲冥想的部分确实不错，让我们学会接受不完美的自己，感受自己的存在。世界上有六十多亿人口，每个人都有自己的活法，不要试图去效仿别人，做独一无二的自己。</p><p>下面还有几本，还没有看完，等看完之后在来更新。<br>《个人印象》<br>《终身成长：重新定义成功的思维模式》<br>《昨日的世界》<br>《终身成长》</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/bookbackage.png&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;记录一些读过的书籍，都颇有感触。&lt;/p&gt;
&lt;p&gt;或许以前读书的境界还没够，还未达到一定的水准。最近每每看书都有很多感慨，读书能让你见识更多。作者把自己的亲身实践，通过文字的形式向我们展示，透过这些文字我们可以直接去借鉴。&lt;/p&gt;
&lt;p&gt;《战后日本经济史》，这本书是讲日本是如何崛起的，其实我们现在的状况跟九几年的日本很相似，想想还未能为祖国做贡献，颇有无奈。&lt;br&gt;
    
    </summary>
    
    
      <category term="闲聊" scheme="http://hanwen.me/tags/%E9%97%B2%E8%81%8A/"/>
    
      <category term="笔记" scheme="http://hanwen.me/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="成长" scheme="http://hanwen.me/tags/%E6%88%90%E9%95%BF/"/>
    
      <category term="读书" scheme="http://hanwen.me/tags/%E8%AF%BB%E4%B9%A6/"/>
    
      <category term="文学" scheme="http://hanwen.me/tags/%E6%96%87%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>投资理财的一些看法</title>
    <link href="http://hanwen.me/2018/10/27/inverst-think/"/>
    <id>http://hanwen.me/2018/10/27/inverst-think/</id>
    <published>2018-10-27T04:18:24.000Z</published>
    <updated>2018-10-27T04:21:16.871Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/SadComputer.jpg" alt="Alt text"><br>这两天看了关于一些投资理财的书籍，可能是这段时间被穷所迫，充满了对 money 的喜爱，要致力于创造属于自己的财富（脑补）。下面是对「邻家的百万富翁」这本书的一些见解，有些内容是从书中摘录的。</p><p>这本书在看着的过程中，传达的思想感觉是节俭，节俭在节俭。并没有在如何投资理财这块做很详细的说明。</p><p>书中主要是对积累财富，衣食住行，教育子女，以及遗产分配等讲解如何获取更多的钱。遗产分配想必在我们这里是不需要考虑太多，大部分都是直接继承，没有所谓的遗产锐等。2016 年我们才引入遗产锐。</p><a id="more"></a><p>在积累财富的过程中，提倡的就是节俭，不要为了虚荣心去花没有必要的钱，年轻的时候有条件的话，就应该为投资理财进行提前规划。书中对百万富翁的调查，发现大部分人都是很节俭的，并没有我们想像中的那样炫富，其中很大一部分都是第一代白手起家起来的。</p><p>书中关于教育子女这块是非常不错的，讲述了如何教会子女，不要成为“经济门诊病人照顾”，学会不依赖于父母，最后能够在金钱上自立。在教育这块也分析了为什么会有富不过三代的这样说法，其实是很有道理的。</p><p>可能会有一些人认为钱是理出来的，而不是省出来的，我也认同这样的观点。当随着我们的收入不断的提高的时候，靠的就是我们是不是能够克已自律，如果在收入增加的时候，也能保持自律，并且能够合理的规划，想必这是最好的结果，本书只是对百万富翁的调查分析。</p><p>富有是一种心态而不是一种形式，可我们往往只注重形式，幻想可以挥金如土，可以尽情享受，希望被别人羡慕和赞许，所以很多人希望速富，渴望地位，渴望别人认可，所以在真正富裕之前，我们总是把自己打扮靓丽，买好车，住高端公寓，没事的时候爱挥挥手腕上的名牌手表、微薄晒晒今天又吃了什么山珍海味，和我们在大街上、电视里、电影里见到看上去是“富人”的人一样。</p><p>可能会有人不赞同上面的说法，因为人生就要享受，趁年轻更加得赶紧去消费，提升自己的生活品质，挣得多理所当然花得多。尤其是在中国，面子有时很重要很重要很重要，但我相信自己不会暴富，估计也没法年薪成百上千万，也不想为了钱在别人面前强颜欢笑，却同时阉割了自己的个性。我相信脚踏实地的不断积累，不需要为了显示自己富有和高贵的品味而去追求那些豪华高端的玩意，就像作者说的，真正的富人不会让你觉得他像个富人，但有个共通的地方，他们都有一个强大的内心世界。</p><p>强大到既不以外表论断他人，也不为自己外在的不足而庸人自扰。要以满足感的延迟来约束自己，过简朴的生活而不抱怨，默默为未来打下坚实的基础。这并非一本励志或洗脑的书，只是通过调查揭示了百万富翁踏实、勇敢、自律的一面，让我们有机会知道，拥有那些华丽的物件不是富有的象征，而自我品格的培养，才是心灵和物质双重富有的唯一出路。</p><p>自我反省中，希望与大家共勉。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/SadComputer.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;这两天看了关于一些投资理财的书籍，可能是这段时间被穷所迫，充满了对 money 的喜爱，要致力于创造属于自己的财富（脑补）。下面是对「邻家的百万富翁」这本书的一些见解，有些内容是从书中摘录的。&lt;/p&gt;
&lt;p&gt;这本书在看着的过程中，传达的思想感觉是节俭，节俭在节俭。并没有在如何投资理财这块做很详细的说明。&lt;/p&gt;
&lt;p&gt;书中主要是对积累财富，衣食住行，教育子女，以及遗产分配等讲解如何获取更多的钱。遗产分配想必在我们这里是不需要考虑太多，大部分都是直接继承，没有所谓的遗产锐等。2016 年我们才引入遗产锐。&lt;/p&gt;
    
    </summary>
    
    
      <category term="投资" scheme="http://hanwen.me/tags/%E6%8A%95%E8%B5%84/"/>
    
      <category term="理财" scheme="http://hanwen.me/tags/%E7%90%86%E8%B4%A2/"/>
    
      <category term="看法" scheme="http://hanwen.me/tags/%E7%9C%8B%E6%B3%95/"/>
    
      <category term="思考" scheme="http://hanwen.me/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="反省" scheme="http://hanwen.me/tags/%E5%8F%8D%E7%9C%81/"/>
    
      <category term="读书" scheme="http://hanwen.me/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>你不努力，就是你的错</title>
    <link href="http://hanwen.me/2018/10/23/work-summary/"/>
    <id>http://hanwen.me/2018/10/23/work-summary/</id>
    <published>2018-10-23T05:50:23.000Z</published>
    <updated>2018-10-23T05:54:04.861Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/work_summary.jpg" alt="Alt text"><br>生活每时每刻都是直播，没有预演，也不需要去猜测下一个时刻会发生什么，做好自己的每一步就行了，其它的就交给时间吧。</p><p>这两天经历了一些事，谈下自己这两天对工作和事业的思考。</p><p>大家选择工作或者未来的事业时，一定要注意两点</p><blockquote><p>1 这是一份具有积累性的工作<br>2 这是你感兴趣的   </p></blockquote><a id="more"></a><p>第一点关于积累，也就是说随着时间越长，你就越值钱，如果你所在的工作职位，没有任何积累性而言，可以考虑一下换了，比如学习，我们从小到大一直都在学习中，而且你也一定相信，现在的你比以前的你更优秀了，如果不是说明你就没有任何学习。</p><p>有句名言说的好，如果你现在不觉得一年前的自己是个傻逼，那说明你这一年没学到什么东西。</p><p>另外投资理财也是很具有积累性的，也是说经验越多越吃香，可以利用自己的经验给自己加成。</p><p>第二点关于兴趣，只有是你感兴趣的事情，你才可能做的更好更多的想着，如果你对它都不感兴趣，三天打鱼，两天晒网想必不会有任何意义，只是在浪费自己的时间，兴趣才是最好的老师，如何你喜欢做这件事，你也会享受做事情，带来的快乐。</p><p>跟打游戏一个性质，为何游戏会让人那么难以控制，就是游戏你感兴趣，你玩的开心。所以还是尽量选择自己感兴趣的事情去做，如果你一开始没有这个条件，那就尽量积累自己，等有资本了再去选择。</p><p>最后想说的，当自己工作步入稳定，如果觉得自己在这一行不能干到专家，那就要想着发展自己的第二项技能，防止自己失业。修炼第二项技能并不是说辞职，专门去在学习一项技能，而是说在业余时间，去修炼跟自己现在的职业相关的技能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/work_summary.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;生活每时每刻都是直播，没有预演，也不需要去猜测下一个时刻会发生什么，做好自己的每一步就行了，其它的就交给时间吧。&lt;/p&gt;
&lt;p&gt;这两天经历了一些事，谈下自己这两天对工作和事业的思考。&lt;/p&gt;
&lt;p&gt;大家选择工作或者未来的事业时，一定要注意两点&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1 这是一份具有积累性的工作&lt;br&gt;2 这是你感兴趣的   &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="兴趣" scheme="http://hanwen.me/tags/%E5%85%B4%E8%B6%A3/"/>
    
      <category term="工作" scheme="http://hanwen.me/tags/%E5%B7%A5%E4%BD%9C/"/>
    
      <category term="感触" scheme="http://hanwen.me/tags/%E6%84%9F%E8%A7%A6/"/>
    
      <category term="积累" scheme="http://hanwen.me/tags/%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="第二技能" scheme="http://hanwen.me/tags/%E7%AC%AC%E4%BA%8C%E6%8A%80%E8%83%BD/"/>
    
      <category term="经历" scheme="http://hanwen.me/tags/%E7%BB%8F%E5%8E%86/"/>
    
  </entry>
  
  <entry>
    <title>每个人都应该至少拼一把</title>
    <link href="http://hanwen.me/2018/06/26/read-think/"/>
    <id>http://hanwen.me/2018/06/26/read-think/</id>
    <published>2018-06-26T13:50:56.000Z</published>
    <updated>2018-06-26T13:59:25.173Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/read_think.png" alt="Alt text"><br>其实，我们每一个人都是有天赋的，只是你没有去挖掘和坚持而已。很多情况下都是不愿努力在一些原本可能做好的事情上去做的更好，其中一个重要的原因就是我们缺乏必要的信念。我们觉得自己从来不具有这样的能力，或者是自认为已经错过了最佳的年龄，现在在学习已经为时已晚，更别说实现了。<br><a id="more"></a><br>还记得我们小时候的梦想吗？又有几个是去坚持和努力实现的，大部分可能早已挥之而去，或者了解了社会，已经对自己说这是不可能实现的，而选择放弃或逃避，过着平常的生活。</p><p>我们每个人都有大量的个人经历可以证明这一点：也许我们曾经梦想过精通某项技艺，但是无论我们多么努力，都无法达成愿望。或者，我们曾经认识的一些人在某些事情总是事半功倍。我们往往会说：“这就是天赋，他们生就如此”。</p><p>这就是我们很多人都面临的问题，不愿作出改变和前进，而还想着自己要是像他们一样努力，也会有同样的成就的。自己却一直停留在原步，其实只要你迈出第一步，可能就会发现停不下来了。在任何时候我们都要保持学习的精神，去坚持和专注性的练习。专注性的练习就是我们每个人天生就有的自然能力，这种能力也就是我们所说的“天赋”。</p><p>一万小时定律，大家可能都听过，也就是不管在任何行业任何领域，你如果坚持了一万小时，你就会在这个领域或行业有所成就，但这并不是每个人都可以做到的，有的人经过了一万个小时，但是还是没有有所成就，那是因为他没有进行刻意的练习。一万小时定律这里说的是仅限于一万小时的刻意练习，而不是其它形式的练习活动。</p><p>当你有刻意的去练习或坚持一项任务时，你会发现自己学习时非常有效率，心情也会非常愉快。比如：你要利用自己的业余时间去学习一项技能或者是爱好，当你设定好计划后，能够坚持下去，并进行刻意的练习，一段时间后会取得不错的效果，这时你自己可能会认为原来自己在这方面也是很有天赋的，这也是一种内在的自我激励，让你不断的前进。</p><p>例如，如果你在一个领域取得了很大的成就，如果让你再去学习其它技能的时候，不是自己擅长的领域，也就是我们不具有刻意练习的天赋时，相信你也一定能在其它领域取得不错的成就。就好比马云如果不去电商了，你也会相信他能在其它领域取得一定的成就。</p><p>我们大多数人只是想要变得更好一些而已，如果想要他人注意到我们的成长过程，我们无需达到接近世界级的水平，一点点进步就会非常明显，这是我们所需要的鼓励和支持，学会去展示自己。</p><p>最后一句简短的对话送给大家。</p><blockquote><p>“当你 100 岁时，你唯一后悔的事情就是，60 岁时没有开始练习小提琴”。</p><p>“如果那样的话，你到现在就有 40 年的演奏经验了”。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/read_think.png&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;其实，我们每一个人都是有天赋的，只是你没有去挖掘和坚持而已。很多情况下都是不愿努力在一些原本可能做好的事情上去做的更好，其中一个重要的原因就是我们缺乏必要的信念。我们觉得自己从来不具有这样的能力，或者是自认为已经错过了最佳的年龄，现在在学习已经为时已晚，更别说实现了。&lt;br&gt;
    
    </summary>
    
    
      <category term="生活" scheme="http://hanwen.me/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="努力" scheme="http://hanwen.me/tags/%E5%8A%AA%E5%8A%9B/"/>
    
      <category term="感悟" scheme="http://hanwen.me/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="天赋" scheme="http://hanwen.me/tags/%E5%A4%A9%E8%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>Servlet API</title>
    <link href="http://hanwen.me/2018/06/21/servlet-api/"/>
    <id>http://hanwen.me/2018/06/21/servlet-api/</id>
    <published>2018-06-21T15:27:43.000Z</published>
    <updated>2018-06-23T14:36:25.639Z</updated>
    
    <content type="html"><![CDATA[<p><code>Sevelt</code> 的框架的核心是 <code>javax.servlet.Servlet</code>接口，所有的<code>Servlet</code>都必须实现这一接口。在<code>Servlet</code>接口中定义了五个方法，其中有三个方法代表了<code>Servlet</code>的生命周期：  </p><a id="more"></a><pre><code>init    方法：负责初始化Servlet对象service    方法：辅助响应客户的请求destroy    方法：当Servlet对象退出生命周期时，负责释放占用的资源</code></pre><p>如果你的<code>Servlet</code>类扩展了<code>HttpServlet</code>类，你通常不必实现<code>service</code>方法，因为<code>HttpServlet</code>类已经实现了<code>service</code>方法，该方法的声明形式如下：  </p><pre><code>protected void service(HttpServletRequest request,HttpServletResponse response)throws ServletException, IOEception;</code></pre><p>在<code>HttpServlet</code>的<code>service</code>方法中，首先从<code>HttpServletRequest</code>对象中获取<code>HTTP</code>请求方式的信息，然后在根据请求方式调用相应的方法。例如：如果请求方式为<code>GET</code>，那么调用<code>doGet</code>方法：如果请求方式为<code>POST</code>，那么调用<code>doPost</code>方法。</p><p>在<code>servlet</code>中为什么可以直接调用<code>req</code>，<code>resp</code>的相应方法：多态，父类型的引用，可以指向子类的对象。</p><p><code>Servlet</code>的生命周期可以分为三个阶段：<br>1、初始化阶段  </p><pre><code>—servlet容器启动时自动装载某些Servlet—在servlet容器启动后，客户首先向Servlet发出请求—Servlet类文件被更新后，重新装载Servlet—Servlet被装载后，Servlet容器创建一个Servlet实例并且调用Servlet的init（）方法进行初始化。在Servlet的整个生命周期中，init方法只会被调用一次。</code></pre><p>2、响应客户请求阶段<br>对于到达<code>Servlet</code>容器的客户请求，<code>Servlet</code>容器创建特定于这个请求的<code>ServletRequest</code>对象和<code>ServletResponse</code>对象，然后调用<code>Servlet</code>的<code>service</code>方法，<code>service</code>方法从<code>ServletRequest</code>对象获得客户请求信息、处理该请求，并通过<code>ServletResponse</code>对象相客户返回响应结果。  </p><p>3、终止阶段<br>当<code>web</code>应用被终止，或<code>Servlet</code>容器终止运行，或<code>Servlet</code>容器重新装载<code>Servlet</code>的新实例时，<code>Servlet</code>容器先调用<code>Servlet</code>的<code>destroy</code>方法，在<code>destroy</code>方法中，可以释放<code>Servlet</code>所占用的资源。</p><p>在<code>javax.servlet.Servlet</code>接口中定义了三个方法</p><pre><code>init()service()destroy()</code></pre><p>他们将分别在<code>Servlet</code>的不同阶段被调用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Sevelt&lt;/code&gt; 的框架的核心是 &lt;code&gt;javax.servlet.Servlet&lt;/code&gt;接口，所有的&lt;code&gt;Servlet&lt;/code&gt;都必须实现这一接口。在&lt;code&gt;Servlet&lt;/code&gt;接口中定义了五个方法，其中有三个方法代表了&lt;code&gt;Servlet&lt;/code&gt;的生命周期：  &lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://hanwen.me/tags/Java/"/>
    
      <category term="Servlet" scheme="http://hanwen.me/tags/Servlet/"/>
    
      <category term="API" scheme="http://hanwen.me/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>如何去学习网络安全</title>
    <link href="http://hanwen.me/2018/06/18/websafe-summary/"/>
    <id>http://hanwen.me/2018/06/18/websafe-summary/</id>
    <published>2018-06-18T11:24:49.000Z</published>
    <updated>2018-06-18T14:52:45.972Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/websafe.jpg" alt="Alt text"><br>　　对于一些不知道怎么去入手学习网络安全的，这里我给出一些学习资料的网址。可以根据这网站里面的视频学习或者通过做里面的挑战来提升自己。遇到不会的，自己可以去Google或百度上搜对应的writeup。然后自己在去实践，这样学习的更快，更有体会。<br>　　<a id="more"></a></p><p>　　1、<a href="http://www.hetianlab.com/" target="_blank" rel="external">合天网络安全实验室</a>　　合天网络安全实验室——里面有各方面的视频，还提供了在线环境的练习，比较适合刚开始学网络安全的人来学习。有的练习是需要合氏币，这个可以通过自己去做里面的练习，会有奖励，还可以每天签到赚合氏币。</p><p>　　2、<a href="http://www.shiyanbar.com/" target="_blank" rel="external">实验吧</a>　　实验吧——这个网站不仅提供了视频的教学还提供了挑战。另外还可以自己出题。</p><p>　　3、<a href="http://www.baimaoxueyuan.com/" target="_blank" rel="external">白帽学院</a>　　白帽学院——快乐学习的平台，这个跟前两个网站差不多。大家自己可以去体验。</p><p>　　4、<a href="http://hackinglab.cn/index.php" target="_blank" rel="external">网络安全实验室</a>　　网络安全实验室——里面有各种练习题，大部分是一些基础题，刚开始练习的可以去多做做。</p><p>　　5、<a href="http://bobao.360.cn/index/index" target="_blank" rel="external">360安全播报</a>　　360安全播报——可以通过这个去搜索对应的writeup，每一届的比赛都会在这上面公布，可以通过这个去关注有哪些比赛，然后去参加去实践。</p><p>　　6、<a href="http://loudong.360.cn/" target="_blank" rel="external">补天</a>　　补天-全球最大的漏洞响应平台——可以通过这个去关注发现的新的漏洞，及时了解最新的信息。</p><p>　　7、<a href="http://oj.xctf.org.cn/" target="_blank" rel="external">XCTF_OJ</a>　　XCTF_OJ——提供了很多练习题库，里面有很多值得去思考的题目，比较有意思，练习的差不多了可以多做做。</p><p>　　8、<a href="http://www.freebuf.com/" target="_blank" rel="external">Freebuf</a>　　——也是比较推荐的网站，属于比较好的，没事的时候可以自己多看看。</p><p>　　9、<a href="http://www.wooyun.org/index.php" target="_blank" rel="external">乌云</a>　　乌云——是国内比较好的漏洞网站啦。</p><p>　　10、<a href="http://www.pediy.com/" target="_blank" rel="external">看雪学院</a>　　看雪学院——里面也有很多文章，无聊的时候也可以看看。</p><p>　　11、<a href="http://www.xfocus.net/index.html" target="_blank" rel="external">xfocus</a>　　——里面提供了各种工具的下载，还有文章。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/websafe.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;　　对于一些不知道怎么去入手学习网络安全的，这里我给出一些学习资料的网址。可以根据这网站里面的视频学习或者通过做里面的挑战来提升自己。遇到不会的，自己可以去Google或百度上搜对应的writeup。然后自己在去实践，这样学习的更快，更有体会。&lt;br&gt;
    
    </summary>
    
    
      <category term="安全" scheme="http://hanwen.me/tags/%E5%AE%89%E5%85%A8/"/>
    
      <category term="网络" scheme="http://hanwen.me/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="黑客" scheme="http://hanwen.me/tags/%E9%BB%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>Java学习路线之四个阶段</title>
    <link href="http://hanwen.me/2018/06/12/java-study-summary/"/>
    <id>http://hanwen.me/2018/06/12/java-study-summary/</id>
    <published>2018-06-12T02:19:24.000Z</published>
    <updated>2018-06-17T02:26:33.572Z</updated>
    
    <content type="html"><![CDATA[<p><img src="../images/java_study_summary.jpg" alt=""><br>写这篇总结，主要是记录下自己的学习经历，算是自己对知识的一个回顾。也给想要学习 Java 的提供一些参考，对于一些想要学习Java，又不知道从哪里下手，以及现在有哪些主流的 Java 技术。想必大家学习一门技术，前期都很想看到一些结果或成就，这样就比较容易激励自己学习下去，最好的办法就是实践，实践，实践！<br><a id="more"></a><br>先说明一下我的情况，我是从大二才开始接触 Java，然后自己摸索，期间真是摸打滚爬过来的。选的是计算机专业，大一的时候还没有自己的笔记本，所以都是听课过来的，了解了一些概念性的东西，课上老师也有演示过一些程序，懂得思考之后，发现计算机有很多有趣的地方，比如想知道这个东西是如何实现的，为什么会出现这些东西。真不是知道当初天天打游戏的时候，为什么没有发现，要是发现的话，现在说不定早就那啥那啥了。到了大二的时候自己有了笔记本之后，就开始自己摸索，很好奇自己当初拿到笔记本竟然没有去打游戏，而是用来学习。下面开始说正事。</p><h3 id="选语言"><a href="#选语言" class="headerlink" title="选语言"></a>选语言</h3><p>开始学习的时候，经过自己搜索之后，发现有很多种语言，自己完全处于懵逼状态，不知道选哪个，也不知道每种语言都可以用来干什么，后来经过学长的指点还有身边的人都说 Java 好，自己慢慢的就入坑了。在选择要学习一门语言的时候，一定要选自己感兴趣的，而且要有自己的目标，不然的话，后期很难坚持下来，除非你有很强的自律性。每个人前进都是有自己的驱动力，所以找到属于自己的驱动力，才能保证你不断的进步。</p><h3 id="Java第一阶段"><a href="#Java第一阶段" class="headerlink" title="Java第一阶段"></a>Java第一阶段</h3><p>刚接触 Java 的时候，想必大家都是从环境配置开始的，这个里面的坑想必大家都踩过。对于还没有开始的同学，也有可能会经历这个阶段，说可能是因为现在的 Java1.6 之后安装默认是加到环境变量里面的，但是在安装过程中有可能会出现一些意外情况，导致不能加入成功，这是就需要我们手动加入了。在这里特说明下，在大学期间一定要把一些基础的课程学好，比如：计算机系统、算法、编译原理等，这个对后期的学习会有很大的影响，最简单的就是你在添加环境变量的时候，为什么要把路径添加到 Path 下面，而不是添加到其它下面，计算机是如何去识别访问这些东西。</p><p>我一开始学习 Java 的时候，是学长分享的视频，这个视频的好处就是在学习 Java 基础的时候，完全脱离一些集成的工具，就是用编辑器（notepad++）写好程序，手动通过命令行去编译，再执行，让你能够了解其中的原理，以及锻炼自己的动手能力。如果一上来就上你用 Eclipse 或者其它工具，把一些底层的东西屏蔽掉，开始学习的时候大家可能连 class 文件都没有见过，只是知道写了这行代码，运行之后它会出来什么结果。</p><p>这里给出我当初学习的视频，有点老但是基础知识都是一样的。学习 Java 基础知识的时候，应该多动手，多思考，很多时候，你想当然的事情，等你写出来运行一下，你就会发现不是这么一回事，不信你就试试。在学习视频的时候，有两种学习方法建议：方法一先把视频过一篇，在看视频的时候，记下知识点，看完视频之后，自己对着知识点，自己敲代码实现，实在想不出来的，回过头来在看视频。方法二边看视频边跟着敲代码，这样会比第一种方法相对容易一些，但是如果是这种方法学习的话，要记得回头多复习，不然很容易忘记。两种方法各有好处，第一种方法一开始学习比较慢，但是后面基础有了之后，就会上手很快，而且记得很牢固。第二种方法比第一种方法花的时间要相对的少一些，所以需要我们反复的去回顾。学习完以上内容之后，你应该对 Java 有了一定的了解，你可以使用 Java 语言写出来一些简单的程序，并且是使用最简单的编辑器。这个时候，可以不用着急进入下个阶段，给自己一两天的时间，对学习过的知识进行下总结。</p><p>在学习的过程中，你应该注重下面这些知识点，由于是自己总结的，有可能会有不对的地方，若有不对之处，还请指出。</p><h4 id="知识点梳理："><a href="#知识点梳理：" class="headerlink" title="知识点梳理："></a>知识点梳理：</h4><p><strong>概念</strong>：面向对象的三大基本特征五大基本原则（当初让学长考我的时候第一个问的就是这个）、面向对象、面向过程、什么是多态、什么是继承、什么是封装。</p><p><strong>集合</strong>：Collection 集合、List 集合、Set 集合、Map 集合</p><p><strong>异常</strong>：Java 中异常处理机制和应用，自定义异常</p><p><strong>IO</strong>：File 类，字符流、字节流、转换流、缓冲流、递归</p><p><strong>网络编程</strong>：Socket</p><p><strong>线程</strong>：线程的生命周期，Java 线程池，线程同步问题，线程死锁问题</p><p><strong>继承和接口</strong>：Class，Interface</p><p><strong>反射</strong>：动态代理</p><p><strong>Mysql 和 JDBC 开发</strong>：Mysql 数据库，JDBC，DBUtils，DBCP连接池</p><p><strong>书籍推荐</strong>：Head First Java, Java核心技术</p><p>视频获取：微信后台回复「javaweb学习资料」包含后面三个阶段。</p><h3 id="Java-第二阶段"><a href="#Java-第二阶段" class="headerlink" title="Java 第二阶段"></a>Java 第二阶段</h3><p>Java 基础学习完之后，我是开始学习 Javaweb，在一开始的几天比较迷茫，因为感觉自己写的东西没有用处，比如写个计算器什么的，生活中没有什么用，可能是太过于看结果导致的。这个时候应该去做一些有趣的事情，学习新的知识，开发新的大陆，这就是我们的 Web 开发了，主要包括前端页面（HTML/CSS/JS），Servlet/JSP，以及 Mysql 相关的知识。这些视频在上面分享的视频里面已经包括了。</p><p>关于页面，这些内容对于 Java 后端来说，不是特别重要，但是你应该尽自己的最大能力让它漂亮，最起码可以入眼，这样的话，页面就不是什么问题了。接下来，就是学习的重头戏了，学习 Servlet/JSP 部分，这也是 Java 后端开发必须非常精通的部分，在学习 Web 这三部分的时候，这个部分是最花时间的。这个阶段学习的时候，要学会使用开发工具，比如 Eclipse 或者 IDEA 来学习。最后一部分，你就要学会使用数据库，Mysql 数据库是不错的入门选择，而且 Java 领域主流的关系型数据就是 Mysql，这部分其实你在学习 JDBC 的时候，就会接触到，因为 JDBC 也是属于数据库的一部分。不仅要学会使用 JDBC 操纵数据库，而且还要学会使用数据库客户端工具，比如 sqlyog，navicat 等。</p><h4 id="知识点梳理：-1"><a href="#知识点梳理：-1" class="headerlink" title="知识点梳理："></a>知识点梳理：</h4><p><strong>前端技术</strong>：HTML、CSS、JS、JQuery、Bootstrap</p><p><strong>JavaWeb 核心内容</strong>：Servlet、JSP、XML、HTTP、Ajax、过滤器、拦截器等</p><p><strong>Mysql 和 JDB</strong>C：复习</p><p><strong>推荐书籍</strong>：相关的 Web 书籍都可以，可以顺带着看 Java 编程思想</p><h3 id="Java-第三阶段"><a href="#Java-第三阶段" class="headerlink" title="Java 第三阶段"></a>Java 第三阶段</h3><p>这个阶段是在你掌握第二阶段之后开始，如果学习了第二个阶段之后想找工作的话，还需要在学习一些主流的框架知识。目前比较主流的框架是 SSM 框架，既 Spring，SpringMVC，Mybatis。要学会这些框架的搭建，以及用它们作出一个简单的 WEB 项目，包括增删改查的功能。在这里一开始，你可以不用太去关心那些配置文件，以及为什么会这样配置，这个可以留到后面慢慢了解，开始的时候先让自己有个体验，激励自己学习的动力。</p><p>搭建这三个框架的时候，一定要记录自己搭建的过程，这个在你工作之后肯定会用到的。在搭建的过程，我们通过网上查找资料或是跟着视频学习，都会接触到 Maven 这个工具，这个工具在你工作之后，也一定会用到的，可以顺带着了解，你不一定要去完全掌握，只要学会使用，知道基本原理就可以。学会使用之后，自己要跟着老师或者从网上去理解更多的东西，比如那些配置文件等。</p><h4 id="知识点梳理：-2"><a href="#知识点梳理：-2" class="headerlink" title="知识点梳理："></a>知识点梳理：</h4><p><strong>Spring 框架</strong>：配置文件、IoC 思想、DI 依赖注入、面向切面编程、事务等。</p><p><strong>SpringMVC</strong>：框架原理、交互、拦截器等。</p><p><strong>Maven</strong>：安装使用、基本操作。</p><p><strong>Mybatis</strong>：框架原理、Mybatis 开发 DAO 方式、与其它框架的整合。</p><p><strong>推荐书籍</strong>：Spring 实战，Effective Java，Java 编程思想</p><h3 id="Java-第四阶段"><a href="#Java-第四阶段" class="headerlink" title="Java 第四阶段"></a>Java 第四阶段</h3><p>这个时候相信你已经能够完成独立开发，并且也工作了，对付工作上面的时候，你的技术一定是可以的。但是这个时候不要对自己进行松懈，你要继续学习，而不是工作只是为了应对工作，你应该提升自己的价值。这个时候可以去看一些比较底层的书籍，比如《深入理解Java虚拟机》，这本书就是全面帮助你了解 Java 虚拟机，这个时候想必你一定知道 Java 是运行在 JVM 上的，你没有任何理由不去了解 JVM。另外，关于并发这方面，推荐《Java并发编程实战》，这本书啃完之后，对并发的理解应该有一定的体会了。</p><p>这个阶段要做的远不止这些，我们要去思考我们之前使用的那些框架是怎么回事，以及阅读 Java 经典的一些源码，看懂源码的前提，就是你已经有了一定的基础，当然有基础也不一定一下子就能看懂，看不懂就要去思考，在看源码的过程中，你可能有各种各样的疑问，有疑问就是对的，问自己最多的应该是这里问什么会这样写，而不是那样写吧。这个阶段需要自己对自己有很强的自律去学习，不要看了一半就放弃了。学会看源码之后，自己可以尝试着模仿别人写的比较好的开源项目，造属于自己的轮子，虽说不一定有用，但是对提升自己有一定的好处。</p><p>如果你想成为优秀的人，你就要「能别人不能」，也就是说你要找到属于自己的一个领域研究下去，以期在将来，你能够成为这个领域的专家，建立起你的差异性。</p><p>最后，请记住，从你入行那一刻起，你就要比别人努力，就要不停的学习。每个人在学习的过程中都有自己的一种方式，在学习的过程中，要学会自己去判断。其实生活中也是一样的，你身边的人形形色色，有的人你喜欢，有的人你讨厌，但是你喜欢的人身上也有缺点，你讨厌的人身上也有其优点，这个时候你要学会从他们身上学习他们的优点，让自己变的更优秀。</p><p>PS：如果觉得文章不错的话，还请大家点赞分享下，算是对我的最大支持，我的微信公众号是「funnyZhang」欢迎大家打扰。<br><img src="../images/qr.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;../images/java_study_summary.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;写这篇总结，主要是记录下自己的学习经历，算是自己对知识的一个回顾。也给想要学习 Java 的提供一些参考，对于一些想要学习Java，又不知道从哪里下手，以及现在有哪些主流的 Java 技术。想必大家学习一门技术，前期都很想看到一些结果或成就，这样就比较容易激励自己学习下去，最好的办法就是实践，实践，实践！&lt;br&gt;
    
    </summary>
    
    
      <category term="总结" scheme="http://hanwen.me/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="Java" scheme="http://hanwen.me/tags/Java/"/>
    
      <category term="心得" scheme="http://hanwen.me/tags/%E5%BF%83%E5%BE%97/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS——SSL配置与实现</title>
    <link href="http://hanwen.me/2018/05/22/config-ssl/"/>
    <id>http://hanwen.me/2018/05/22/config-ssl/</id>
    <published>2018-05-22T10:14:18.000Z</published>
    <updated>2018-05-29T15:11:57.446Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、在对应的云服务器上可以申请到免费的-SSL-证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择-SSL-证书，我们选择其中的域名型免费版（DV）。"><a href="#1、在对应的云服务器上可以申请到免费的-SSL-证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择-SSL-证书，我们选择其中的域名型免费版（DV）。" class="headerlink" title="1、在对应的云服务器上可以申请到免费的 SSL 证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择 SSL 证书，我们选择其中的域名型免费版（DV）。"></a>1、在对应的云服务器上可以申请到免费的 SSL 证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择 SSL 证书，我们选择其中的域名型免费版（DV）。</h4><a id="more"></a><p><img src="../images/ssl1.png" alt="">  </p><h4 id="2、填写申请的信息，填写信息之后，确认申请。申请之后，可以选择自动添加解析，也可以手动添加解析，之后后台是机器审核扫描-CA-证书，时间很快，通过之后，会颁发证书，然后我们就可以去使用证书了。"><a href="#2、填写申请的信息，填写信息之后，确认申请。申请之后，可以选择自动添加解析，也可以手动添加解析，之后后台是机器审核扫描-CA-证书，时间很快，通过之后，会颁发证书，然后我们就可以去使用证书了。" class="headerlink" title="2、填写申请的信息，填写信息之后，确认申请。申请之后，可以选择自动添加解析，也可以手动添加解析，之后后台是机器审核扫描 CA 证书，时间很快，通过之后，会颁发证书，然后我们就可以去使用证书了。"></a>2、填写申请的信息，填写信息之后，确认申请。申请之后，可以选择自动添加解析，也可以手动添加解析，之后后台是机器审核扫描 CA 证书，时间很快，通过之后，会颁发证书，然后我们就可以去使用证书了。</h4><p><img src="../images/ssl2.png" alt=""></p><h4 id="3、配置网站，能够使用-HTTPS-访问，这里以-Nginx-部署为例。"><a href="#3、配置网站，能够使用-HTTPS-访问，这里以-Nginx-部署为例。" class="headerlink" title="3、配置网站，能够使用 HTTPS 访问，这里以 Nginx 部署为例。"></a>3、配置网站，能够使用 HTTPS 访问，这里以 Nginx 部署为例。</h4><h5 id="3-1-获取证书"><a href="#3-1-获取证书" class="headerlink" title="3.1 获取证书"></a>3.1 获取证书</h5><p>我们在第二步中，可以将证书下载下来，里面有关于 Nginx 的证书。包括</p><pre><code>1_www.domain.com_bundle.crt //证书2_www.domain.com.key         //私钥文件  </code></pre><p>1__www.domain.com_bundle.crt 文件包括两段证书代码 </p><pre><code>“-----BEGIN CERTIFICATE-----”和“-----END CERTIFICATE-----”</code></pre><p>2_www.domain.com.key 文件包括一段私钥代码</p><pre><code>“-----BEGIN RSA PRIVATE KEY-----”和“-----END RSA PRIVATE KEY-----”。</code></pre><h5 id="3-2-证书安装"><a href="#3-2-证书安装" class="headerlink" title="3.2 证书安装"></a>3.2 证书安装</h5><p>将域名 <code>www.domain.com</code> 的证书文件 <code>1_www.domain.com_bundle.crt</code>、私钥文件<code>2_www.domain.com.key</code>保存到同一个目录，例如<code>/usr/local/nginx/conf</code>目录下。<br>更新 Nginx 根目录下 <code>conf/nginx.conf</code> 文件如下：</p><pre><code>server {    listen 443;    server_name www.domain.com; #填写绑定证书的域名    ssl on;    ssl_certificate 1_www.domain.com_bundle.crt;    ssl_certificate_key 2_www.domain.com.key;    ssl_session_timeout 5m;    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置    ssl_prefer_server_ciphers on;    location / {        root   html; #站点目录        index  index.html index.htm;    }}</code></pre><p>配置完成后，先用<code>bin/nginx –t</code>来测试下配置是否有误，正确无误的话，重启 nginx。就可以使 <a href="https://www.domain.com" target="_blank" rel="external">https://www.domain.com</a> 来访问了。配置文件参数如下  </p><p><img src="../images/ssl3.png" alt=""></p><h5 id="4-使用全站加密，http-自动跳转-https（可选）"><a href="#4-使用全站加密，http-自动跳转-https（可选）" class="headerlink" title="4 使用全站加密，http 自动跳转 https（可选）"></a>4 使用全站加密，http 自动跳转 https（可选）</h5><p>对于用户不知道网站可以进行 https 访问的情况下，让服务器自动把 http 的请求重定向到 https。<br>在服务器这边的话配置的话，可以在页面里加 js 脚本，也可以在后端程序里写重定向，当然也可以在web服务器来实现跳转。Nginx 是支持 rewrite 的（只要在编译的时候没有去掉pcre）<br>在 http 的 server 里增加 <code>rewrite ^(.*) https://$host$1 permanent</code>;<br>这样就可以实现 80 进来的请求，重定向为 https 了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;1、在对应的云服务器上可以申请到免费的-SSL-证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择-SSL-证书，我们选择其中的域名型免费版（DV）。&quot;&gt;&lt;a href=&quot;#1、在对应的云服务器上可以申请到免费的-SSL-证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择-SSL-证书，我们选择其中的域名型免费版（DV）。&quot; class=&quot;headerlink&quot; title=&quot;1、在对应的云服务器上可以申请到免费的 SSL 证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择 SSL 证书，我们选择其中的域名型免费版（DV）。&quot;&gt;&lt;/a&gt;1、在对应的云服务器上可以申请到免费的 SSL 证书，这里以腾讯云为例说明。进入腾讯云后台，在产品列表中选择 SSL 证书，我们选择其中的域名型免费版（DV）。&lt;/h4&gt;
    
    </summary>
    
    
      <category term="SSL证书" scheme="http://hanwen.me/tags/SSL%E8%AF%81%E4%B9%A6/"/>
    
      <category term="HTTPS" scheme="http://hanwen.me/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>Mac下安装Django并验证是否安装成功</title>
    <link href="http://hanwen.me/2018/05/03/django-install-for-mac/"/>
    <id>http://hanwen.me/2018/05/03/django-install-for-mac/</id>
    <published>2018-05-03T12:54:44.000Z</published>
    <updated>2018-05-03T13:14:20.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>登录<code>Django</code>官网<a href="https://github.com/django/django/releases" target="_blank" rel="external">或者通过这里</a>下载需要的文件，<code>Mac</code>下面我们可以下载对应的<code>tar.gz</code>文件。<font color="red">注：</font>在下载<code>Django</code>的时候要注意下载的版本和<code>python</code>版本之间的支持。</p></li><li><p>将下载的文件移动到我们需要安装的目录中，自己可以放在一个单独存放软件的文件夹下（这里不一定是系统默认的安装路径）可以自己新建。在<code>shell</code>命令行中进入下载好的<code>django-2.0.tar.gz</code>文件目录中，执行下面的命令，进行解压。  </p><pre><code>tar -zxvf django-2.0.tar.gz</code></pre><a id="more"></a></li><li><p>解压之后，会在该目录出现<code>django-2.0.5</code>文件夹，然后我们进入该文件夹，执行安装。</p><pre><code>python setup.py install</code></pre></li><li><p>安装完成之后，我们设置下环境变量，因为不设置环境变量的话，在后面执行的话会出现一些小的问题。</p></li><li><p>编辑<code>.bashrc</code>或者是<code>ect/profile</code>文件，在文件中加入我们的<code>Django</code>安装目录，在查看安装目录的时候，我们可以使用<code>pwd</code>来查看当前的路径，即可显示当前目录，加入下面两行即可。 </p><pre><code>export DJANGO_HOME=/Users/zhanghanwen/Tools/django-2.0.5/djangoexport PATH=$PATH:$DJANGO_HOME/bin</code></pre></li><li>至此，我们的安装就完成了，接下来我们在<code>python</code>命令行中进行验证是否安装成功。</li><li><p>在命令行中输入<code>python</code>进入<code>python</code>环境下</p><pre><code>&gt;&gt;&gt; import django&gt;&gt;&gt; django.get_version()&apos;2.0.5&apos;</code></pre></li><li>返回正确的版本，说明我们安装成功。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;登录&lt;code&gt;Django&lt;/code&gt;官网&lt;a href=&quot;https://github.com/django/django/releases&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;或者通过这里&lt;/a&gt;下载需要的文件，&lt;code&gt;Mac&lt;/code&gt;下面我们可以下载对应的&lt;code&gt;tar.gz&lt;/code&gt;文件。&lt;font color=&quot;red&quot;&gt;注：&lt;/font&gt;在下载&lt;code&gt;Django&lt;/code&gt;的时候要注意下载的版本和&lt;code&gt;python&lt;/code&gt;版本之间的支持。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将下载的文件移动到我们需要安装的目录中，自己可以放在一个单独存放软件的文件夹下（这里不一定是系统默认的安装路径）可以自己新建。在&lt;code&gt;shell&lt;/code&gt;命令行中进入下载好的&lt;code&gt;django-2.0.tar.gz&lt;/code&gt;文件目录中，执行下面的命令，进行解压。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tar -zxvf django-2.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="Django" scheme="http://hanwen.me/tags/Django/"/>
    
      <category term="Python" scheme="http://hanwen.me/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>去除Tensorflow的警告信息</title>
    <link href="http://hanwen.me/2018/01/15/remove-waring/"/>
    <id>http://hanwen.me/2018/01/15/remove-waring/</id>
    <published>2018-01-15T02:54:27.000Z</published>
    <updated>2018-01-15T03:36:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>使用<code>tensorflow</code>运行程序会提示以下警告信息，但是并不影响运行。警告信息如下</p><pre><code>2018-01-15 10:56:22.537770: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2018-01-15 10:56:22.537796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.2018-01-15 10:56:22.537802: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.2018-01-15 10:56:22.537809: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&apos;t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.</code></pre><p>这个警告是告诉我们可以用自己机器的CPU来进行计算，会得到更好的性能。原因是我直接使用<code>pycharm</code>里面的<code>plugs</code>直接安装的，所以没有去安装对应的模块。去除这个警告我们可以有两种方法，一种是忽略这个警告信息，另一种就是根据提示信息，使用<code>CPU</code>进行计算。这里给出第一种的解决方法。第二种的解决方法大家可以去搜索一下。<br><a id="more"></a><br><strong>解决办法：</strong></p><pre><code># 在代码的开始加入下面两行代码# 也就是对应的日志级别，1 代表是 info， 2 代表是 warning# 改为 warning 就可以忽略上面的警告信息 import osos.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;]=&apos;2&apos;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用&lt;code&gt;tensorflow&lt;/code&gt;运行程序会提示以下警告信息，但是并不影响运行。警告信息如下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2018-01-15 10:56:22.537770: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&amp;apos;t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-15 10:56:22.537796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&amp;apos;t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-15 10:56:22.537802: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&amp;apos;t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-15 10:56:22.537809: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&amp;apos;t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个警告是告诉我们可以用自己机器的CPU来进行计算，会得到更好的性能。原因是我直接使用&lt;code&gt;pycharm&lt;/code&gt;里面的&lt;code&gt;plugs&lt;/code&gt;直接安装的，所以没有去安装对应的模块。去除这个警告我们可以有两种方法，一种是忽略这个警告信息，另一种就是根据提示信息，使用&lt;code&gt;CPU&lt;/code&gt;进行计算。这里给出第一种的解决方法。第二种的解决方法大家可以去搜索一下。&lt;br&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://hanwen.me/tags/Python/"/>
    
      <category term="Tensorflow" scheme="http://hanwen.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>去除Myeclipse中的拼写检查</title>
    <link href="http://hanwen.me/2017/12/27/get-rid-of-myeclipse-spell-wrong/"/>
    <id>http://hanwen.me/2017/12/27/get-rid-of-myeclipse-spell-wrong/</id>
    <published>2017-12-27T14:47:58.000Z</published>
    <updated>2017-12-27T14:51:05.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>myeclipse</code> -&gt; <code>proferences</code> -&gt; <code>general</code> -&gt; <code>editor</code> -&gt; <code>text editors</code> -&gt; <code>spelling</code>  </p><p>然后把<code>enable spell checking</code> 这行对号去掉就行了。  </p><p>改变字体在，<code>colors and fonts</code> -&gt; <code>basic</code> -&gt; <code>text font</code> 选择<code>edit</code>，然后修改自己喜欢的字体和大小即可。  </p><a id="more"></a><p>修改快捷键<br><code>myeclipse</code> -&gt; <code>proferences</code> -&gt; <code>key</code> 然后搜索<code>content assist</code> ，按住<code>alt + /</code>  </p><p><code>ctrl + shift + F</code> 是格式化  </p><p>如何改变<code>jsp</code>里面的编码格式，<br>在项目工程上面右击，<code>proferences</code>-&gt;<code>myeclipse</code>-&gt;<code>Resource</code>，在里面更改编码格式，也可以在<code>winows</code>-&gt;<code>proferences</code>里面进行更改。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;myeclipse&lt;/code&gt; -&amp;gt; &lt;code&gt;proferences&lt;/code&gt; -&amp;gt; &lt;code&gt;general&lt;/code&gt; -&amp;gt; &lt;code&gt;editor&lt;/code&gt; -&amp;gt; &lt;code&gt;text editors&lt;/code&gt; -&amp;gt; &lt;code&gt;spelling&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;然后把&lt;code&gt;enable spell checking&lt;/code&gt; 这行对号去掉就行了。  &lt;/p&gt;
&lt;p&gt;改变字体在，&lt;code&gt;colors and fonts&lt;/code&gt; -&amp;gt; &lt;code&gt;basic&lt;/code&gt; -&amp;gt; &lt;code&gt;text font&lt;/code&gt; 选择&lt;code&gt;edit&lt;/code&gt;，然后修改自己喜欢的字体和大小即可。  &lt;/p&gt;
    
    </summary>
    
    
      <category term="Myeclipse" scheme="http://hanwen.me/tags/Myeclipse/"/>
    
      <category term="实用" scheme="http://hanwen.me/tags/%E5%AE%9E%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>hadoop-spark-hbase集群搭建</title>
    <link href="http://hanwen.me/2017/12/27/hadoop-spark-zookeeper-hbase-cluster/"/>
    <id>http://hanwen.me/2017/12/27/hadoop-spark-zookeeper-hbase-cluster/</id>
    <published>2017-12-27T14:47:58.000Z</published>
    <updated>2018-01-13T03:10:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>根据项目需求我们搭建了一套<code>Hadoop</code> + <code>Spark</code> + <code>Hbase</code> + <code>Hive</code>的架构方案。目前服务器总共有六台，每台服务器有五块硬盘，大小分别是<code>300G</code>、<code>300G</code>、<code>4T</code>、<code>4T</code>、<code>4T</code>，各个服务器主机名分别为<code>Cloud</code>、<code>Cloud2</code>、<code>Cloud3</code>、<code>Cloud4</code>、<code>Cloud5</code>、<code>Cloud6</code>。具体使用情况分别如下表：</p><table><thead><tr><th></th><th style="text-align:center">Cloud</th><th style="text-align:right">Cloud2</th><th style="text-align:right">Cloud3</th><th style="text-align:right">Cloud4</th><th style="text-align:right">Cloud5</th><th style="text-align:right">Cloud6</th></tr></thead><tbody><tr><td><code>300G</code></td><td style="text-align:center">系统</td><td style="text-align:right">系统</td><td style="text-align:right">系统</td><td style="text-align:right">系统</td><td style="text-align:right">系统</td><td style="text-align:right">系统</td></tr><tr><td><code>300G</code></td><td style="text-align:center">软件</td><td style="text-align:right">软件</td><td style="text-align:right">软件</td><td style="text-align:right">软件</td><td style="text-align:right">软件</td><td style="text-align:right">软件</td></tr><tr><td><code>4T</code></td><td style="text-align:center">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td></tr><tr><td><code>4T</code></td><td style="text-align:center">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td><td style="text-align:right">存储数据</td></tr><tr><td><code>4T</code></td><td style="text-align:center">备份</td><td style="text-align:right">备份</td><td style="text-align:right">备份</td><td style="text-align:right">备份</td><td style="text-align:right">备份</td><td style="text-align:right">备份</td></tr></tbody></table><p>每台服务器都是<code>centos7</code>的系统，配置完全相同。项目架构所需要安装的软件和各个服务器上所运行的服务具体情况如下表，由于学校不能申请过多的临时<code>IP</code>地址，所以这里先使用内网地址配置，后期会更改为正式<code>IP</code>。<br><a id="more"></a></p><table><thead><tr><th></th><th style="text-align:center">Cloud</th><th style="text-align:right">Cloud2</th><th style="text-align:right">Cloud3</th><th style="text-align:right">Cloud4</th><th style="text-align:right">Cloud5</th><th style="text-align:right">Cloud6</th></tr></thead><tbody><tr><td><code>IP</code></td><td style="text-align:center"><code>192.168.1.100</code></td><td style="text-align:right"><code>192.168.1.101</code></td><td style="text-align:right"><code>192.168.1.102</code></td><td style="text-align:right"><code>192.168.1.103</code></td><td style="text-align:right"><code>192.168.1.104</code></td><td style="text-align:right"><code>192.168.1.105</code></td></tr><tr><td>安装的软件</td><td style="text-align:center">jdk hadoop hbase spark hive</td><td style="text-align:right">jdk hadoop spark hbase</td><td style="text-align:right">jdk hadoop spark hbase</td><td style="text-align:right">jdk hadoop zookeeper</td><td style="text-align:right">jdk hadoop zookeeper</td><td style="text-align:right">jdk hadoop zookeeper</td></tr><tr><td><code>hadoop</code>的服务</td><td style="text-align:center">Namenode DFSZKFailoverController</td><td style="text-align:right">Namenode DFSZKFailoverController</td><td style="text-align:right">ResourceManager</td><td style="text-align:right">DataNode NodeManager JournalNode</td><td style="text-align:right">DataNode NodeManager JournalNode</td><td style="text-align:right">DataNode NodeManager JournalNode</td></tr><tr><td><code>hbase</code>的服务</td><td style="text-align:center">HMaster</td><td style="text-align:right">HRegionServer</td><td style="text-align:right">HRegionServer</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td></tr><tr><td><code>spark</code>的服务</td><td style="text-align:center">Master</td><td style="text-align:right">Worker</td><td style="text-align:right">Worker</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td></tr><tr><td><code>zookeeper</code>的服务</td><td style="text-align:center"></td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right">QuorumPeerMain</td><td style="text-align:right">QuorumPeerMain</td><td style="text-align:right">QuorumPeerMain</td></tr><tr><td><code>Tomcat</code>的服务</td><td style="text-align:center">项目后台</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td></tr></tbody></table><p>该项目中配置了<code>HA</code>机制，以保证项目的连续性解决方案。首先先说明下什么是<code>HA</code>。<br>　　<code>HA</code>意为<code>High Available</code>，高可用性集群，是保证项目连续性的有效解决方案，一般有两个或两个以上的节点，且分为活动节点及备用节点。通常把正在执行业务的称为活动节点，而作为活动节点的一个备份的则称为备用节点。当活动节点出现问题，导致正在运行的业务（任务）不能正常运行时，备用节点此时就会侦测到，并立即接续活动节点来执行业务。从而实现业务的不中断或短暂中断。<br>　　<code>Hadoop</code>的<code>HA</code>机制需要<code>zookeeper</code>来配合使用。架构图如下<br>　　<img src="./images/frame.jpg" alt=""><br><strong>说明：</strong><br>　　在<code>hadoop2.x</code>中通常由两个<code>NameNode</code>组成，一个处于<code>active</code>状态，另一个处于<code>standby</code>状态。<code>Active NameNode</code>对外提供服务，而<code>Standby NameNode</code>则不对外提供服务，仅同步<code>active namenode</code>的状态，以便能够在它失败时快速进行切换。<br>　　<code>hadoop2.x</code>官方提供了两种<code>HDFS HA</code>的解决方案，一种是<code>NFS</code>，另一种是<code>QJM</code>。这里我们使用简单的<code>QJM</code>。在该方案中，主备<code>NameNode</code>之间通过一组<code>JournalNode</code>同步元数据信息，一条数据只要成功写入多数<code>JournalNode</code>即认为写入成功。通常配置奇数个<code>JournalNode</code>,这里还配置了一个<code>zookeeper</code>集群，用于<code>ZKFC（DFSZKFailoverController）</code>故障转移，当<code>Active NameNode</code>挂掉了，会自动切换<code>Standby NameNode</code>为<code>standby</code>状态。  </p><h2 id="整个架构搭建的具体过程"><a href="#整个架构搭建的具体过程" class="headerlink" title="整个架构搭建的具体过程"></a>整个架构搭建的具体过程</h2><h4 id="前期准备工作"><a href="#前期准备工作" class="headerlink" title="前期准备工作"></a>前期准备工作</h4><p>前期准备工作需要在每台服务器都要去执行。    </p><ol><li><p>修改服务器主机名<br>为了不重启系统而是修改主机名生效，并且保证系统重启之后，不会丢失所做的修改，我们使用以下的方式来修改主机名。  </p><pre><code>vi ／etc/sysconfig/network   //将 HOSTNAME 修改为 Cloud....NETWORKING=yes NETWORKING_IPV6=yes HOSTNAME=Cloud</code></pre><p>然后在执行执行以下命令  </p><pre><code>// sysctl 是 centos7 以后才有的，请不要在 centos7 版本以下使用sysctl kernel.hostname=Cloud  </code></pre><p>执行上述命令之后，在当前终端会话并不会生效，需要重新打开新的会话才会生效。系统重启也不会失效。将上述的两条命令分别在其它的服务器上都执行一遍。<br><font color="red">注意</font>：需要将主机名更换    </p><pre><code>vi ／etc/sysconfig/network    HOSTNAME=Cloud2  //分别也在另外四台服务器上设置//分别为Cloud3、Cloud4、Cloud5、Cloud6</code></pre><p>新会话有效  </p><pre><code> sysctl kernel.hostname=Cloud2  //分别也在另外四台服务器上设置//分别为Cloud3、Cloud4、Cloud5、Cloud6</code></pre></li></ol><ol><li><p>修改<code>IP</code><br>具体的网卡名称依服务器上为准，一般是以<code>ifcfg-</code>开头,<code>ifcfg-lo</code>是<code>LOOPBACK</code>网络不用做任何设置。<code>ip</code>地址和网关依查到的为准，若是虚拟机安装的话，自行查看自己本地的地址和网关。</p><pre><code>  vi /etc/sysconfig/network-scripts/ifcfg-*   // 加入以下内容或者更新对应的内容  BOOTPROTO=static #dhcp改为static（修改）ONBOOT=yes #开机启用本配置，一般在最后一行（修改）IPADDR=192.168.1.100 #静态IP（增加）GATEWAY=192.168.1.1  #默认网关，虚拟机安装的话，通常是2，也就是VMnet8的网关设置（增加）NETMASK=255.255.255.0 #子网掩码（增加）DNS1=192.168.1.2 #DNS 配置，虚拟机安装的话，DNS就网关就行，多个DNS网址的话再增加（增加）  </code></pre><p>使用同样的方法，分别在<code>Cloud2</code>、<code>Cloud3</code>、<code>Cloud4</code>、<code>Cloud5</code>、<code>Cloud6</code>执行相同的操作。执行完毕后，可以需要重启网络才能生效。使用以下命令重启网络。</p><pre><code>service network restart</code></pre><p>重启之后，通过下面的命令查看是否配置成功，并进行验证各个服务器之间是否相同，如果要访问外网也同样需要进行验证，在没有设置<code>DNS</code>之前，是不能访问外网的，所以这个时候只需要验证各个服务器之间是否相同即可。</p><pre><code>ip addr # 查看ip地址# 在 Cloud 上验证其它是否能与其它机器互通ping 192.168.1.102 #在分别与102、103、104、105、106进行验证</code></pre></li><li><p>修改<code>DNS</code><br>修改各个服务器的<code>DNS</code>使其能够访问外网，具体修改如下  </p><pre><code>vi /etc/resolv.confnameserver 8.8.8.8nameserver x.x.x.x # 分配的dns直接加上就可以了</code></pre></li><li><p>修改<code>hosts</code><br><code>hosts</code>文件是主机名和<code>IP</code>的映射关系，如果设置了<code>hosts</code>，可以使用主机名，而不需要在使用对应的冗长的<code>IP</code>地址了。具体修改如下,需要在每台服务器上都做如下修改。</p><pre><code>vi /etc/hosts192.168.1.100 Cloud192.168.1.102 Cloud2192.168.1.103 Cloud3192.168.1.104 Cloud4192.168.1.105 Cloud5192.168.1.106 Cloud6</code></pre></li><li><p>关闭防火墙<br>在关闭之前，需要先查看一下当前的状态，使用一下命令查看，该命令同样是在<code>centos7</code>下，<code>centos7</code>以下的版本根据对应的版本查看是如何关闭的。</p><pre><code>systemctl status firewalld  </code></pre><p>使用下面命令禁用  </p><pre><code>systemctl disable firewalld  systemctl stop firewalld   </code></pre><p>关闭SELinux  </p><pre><code># 临时关闭，不用重启机器  setenforce 0  # 永久关闭，以防止下次重启生效  vi /etc/sysconfig/selinux   # 下面为 selinux 文件中需要修改的元素  SELINUX=disabled  </code></pre></li><li><p>设置<code>NTP</code>时间同步<br>设置时间同步之前，需要安装<code>ntp</code>，执行下面的命令安装，若没有<code>yum</code>命令，可以使用<code>apt-get</code>命令，在每台机器上都执行以下命令。</p><pre><code>yum -y install ntp     or  apt-get install ntpntpdate 0.asia.pool.ntp.org # 手动同步</code></pre></li><li><p>配置<code>ssh</code>免登录<br>先检查一下系统是否已经安装了<code>ssh</code>，若没有安装执行对应的命令进行安装，使用下面的命令可以检查是否已经安装。  </p><pre><code>ssh # 回车，若提示找不到该命令，使用下一行的命令进行安装，每台服务器都执行相同的步骤yum install openssh-server # 或着使用apt-get安装也可以  </code></pre><p> 为了集群安全，我们需要先创建一个用户，在该用户下配置免密钥登录，而不是在<code>root</code>用户下配置免密钥登录，这点请注意，不然的话在<code>hadoop</code>用户去启动集群的时候，同样会提示让你输入密码。下面先创建对应的组和用户，<font color="red">注意：</font>在每台服务上都需要创建。具体如下  </p><pre><code>useradd -g hadoop hadoop # 创建hadoop用户，并且加入hadoop用户组，会自动创建hadoop组passwd hadoop # 为hadoop用户创建密码  </code></pre><p> 组和用户添加之后，可以切换到<code>hadoop</code>用户下面，在<code>hadoop</code>用户下执行下面的命令。</p><pre><code>su hadoop # 然后输入密码进入cd ~ # 下面的两行命令需要在每台服务器都执行ssh-keygen -t rsa # 回车会有提示，都按回车就可以cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys # 配置服务器本身公钥和密钥# 同样下面的命令也需要在每台服务器上执行# 实现每台服务器之间的无密钥登录，可以通过手动，也可以通过脚本实现# 因为配置过hosts了，所以下面可以直接使用主机名# 为了方便我们每台服务器之间都做无密钥登录# 配置的时候，提示输入密码ssh-copy-id -i ~/.ssh/id_dsa.pub Cloud2(主机名字) # 同样Cloud3及其它机器都要执行</code></pre></li><li><p>挂载分区和创建应用安装路径<br>先在<code>hadoop</code>用户根目录下创建<code>3</code>个文件夹，分别如下，所有的六台服务器都执行同样的操作。</p></li></ol><pre><code>mkdir software            # 300Gmkdir -p software/app    # 存放安装软件包mkdir -p software/src    # 解压之后的软件mkdir data                # 集群数据存放 4Tmkdir data2                # 预留    4Tmkdir backup            # 备份数据       4T</code></pre><p>文件夹创建之后，将分区挂载到对应的文件夹下，在挂载之前先将分区格式化一下，同样的每台服务器都需要执行下面的命令  </p><pre><code>mkfs -t ext4 /dev/sdb #具体是sdx，取决于系统，可以通过lsblk查看mkfs -t ext4 /dev/sdcmkfs -t ext4 /dev/sdemkfs -t ext4 /dev/sdf</code></pre><p>将对应的分区挂载到刚才创建的四个文夹上，每台服务器都要执行。执行下面的命令  </p><pre><code>mount /dev/sdb software # sdb分区挂载在software目录下mount /dev/sdc data        # sdc分区挂载在data目录下mount /dev/sde data2    # sde分区挂载在data2目录下mount /dev/sdf backup    # sdf分区挂载在backup目录下</code></pre><p>为了防止启动丢失信息，这里我们在永久写入一下。执行下面的命令</p><pre><code>vi /etc/fstab  # 在文件后面加入以下内容/dev/sdb    /home/hadoop/software    ext4    defaults    0 0/dev/sdc    /home/hadoop/data         ext4    defaults    0 0/dev/sde    /home/hadoop/data2       ext4    defaults    0 0/dev/sdf    /home/hadoop/backup      ext4    defaults    0 0</code></pre><p>说明：这个文件<code>1</code>第列就是<code>具体的分区</code>，第<code>2</code>列是<code>分区挂载的目录</code>，第<code>3</code>列是<code>文件格式</code>，第<code>4</code>列是<code>挂载规则</code>，第<code>5</code>列是<code>备份</code>；<code>0</code>为从不备份，或显示上次至今备份之天数；第<code>7</code>列是启动时<code>fsck</code>检查顺序，<code>0</code>为不检查， <code>“/”</code>永远为<code>1</code>;</p><ol><li><p>环境变量约定<br>所有的环境变量设置均在<code>hadoop</code>用户下面配置，即在根目录下的<code>.bashrc</code>中设置，不需要在<code>etc/profile</code>中设置，所以<code>hadoop</code>用户不需要任何的<code>root</code>权限。 修改环境变量之后，不要忘记重新加载配置文件，不然环境变量不会生效。执行下面的命令生效</p><pre><code>source ~/.bashrc  </code></pre></li></ol><h4 id="以上就是执行完成以后，我们的准备工作就算完成了，下面可以开始我们的集群的搭建。"><a href="#以上就是执行完成以后，我们的准备工作就算完成了，下面可以开始我们的集群的搭建。" class="headerlink" title="以上就是执行完成以后，我们的准备工作就算完成了，下面可以开始我们的集群的搭建。"></a>以上就是执行完成以后，我们的准备工作就算完成了，下面可以开始我们的集群的搭建。</h4><h2 id="HADOO集群搭建"><a href="#HADOO集群搭建" class="headerlink" title="HADOO集群搭建"></a>HADOO集群搭建</h2><ol><li><p>安装<code>jdk</code><br><code>jdk</code>使用<code>jdk-8u151-linux-x64.tar.gz</code>，下载好之后，将这个文件移动到<code>/home/hadoop/software/app</code>下。在<code>windwos</code>上下载的软件，可以通过工具上传到服务器上，上传之后做下面的配置安装。安装配置如下</p><pre><code>cd /software/apptar -zxvf jdk-8u151-linux-x64.tar.gzmv jdk-8u151-linux-x64 ../srccd ~vi .bashrc # 在文件最后加入jdk的环境变量export JAVA_HOME=/home/hadoop/software/src/jdk-8u151-linux-x64export PATH=$PATH:$JAVA_HOME/binsource ~/.bashrcjava -version # 验证是否设置成功</code></pre><p>将安装好的<code>jdk</code>同步到其它的五台服务器上。命令如下</p><pre><code>cd /software/src/jdk-8u151-linux-x64rm -rf /doc     # 为了快速的同步，将不要的帮助文档删掉cd ..scp -r /jdk-8u151-linux-x64 hadoop@Cloud2:/home/hadoop/software/srcscp -r /jdk-8u151-linux-x64 hadoop@Cloud3:/home/hadoop/software/srcscp -r /jdk-8u151-linux-x64 hadoop@Cloud4:/home/hadoop/software/srcscp -r /jdk-8u151-linux-x64 hadoop@Cloud5:/home/hadoop/software/srcscp -r /jdk-8u151-linux-x64 hadoop@Cloud6:/home/hadoop/software/srcscp ~/.bashrc hadoop@Cloud2:/home/hadoop/scp ~/.bashrc hadoop@Cloud3:/home/hadoop/scp ~/.bashrc hadoop@Cloud4:/home/hadoop/scp ~/.bashrc hadoop@Cloud5:/home/hadoop/scp ~/.bashrc hadoop@Cloud6:/home/hadoop/</code></pre><p>到此<code>jdk</code>配置完成。</p></li><li><p>安装配置<code>zookeeper</code>集群<br>我们使用<code>zookeeper</code>版本如下<code>zookeeper-3.4.8.tar.gz</code>，下载地址如下<br><a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.5.0-alpha/" target="_blank" rel="external">点击进入下载页面</a>，下载之后都样将其移动到<code>/software/app</code>这个目录下。具体安装配置如下</p><pre><code># 执行下面的操作之前，确保已经将文件上传至服务器上# 若不是在windows下载的，也可以通过wget命令直接下载到服务器上，但是要确保能访问外网cd /software/apptar -zxvf zookeeper-3.4.8.tar.gzmv zookeeper-3.4.8 ../srccd ../srccd zookeeper-3.4.8mkdir datacd conf/mv zoo_sample.cfg zoo.cfgvi zoo.cfg # 修改并添加如下内容dataDir=/home/hadoop/software/src/zookeeper-3.4.8/dataserver.4=Cloud4:2888:3888 # 以下内容是需要添加的server.5=Cloud5:2888:3888server.6=Cloud6:2888:3888ESC键 :wq # 保存并退出cd ../dataecho &quot;4&quot; &gt; myid</code></pre><p>将配置好的<code>zookeeper</code>同步<code>Cloud5</code>和<code>Cloud6</code>服务器上。</p><pre><code>cd ~scp -r /software/src/zookeeper-3.4.8 hadoop@Cloud5:/home/hadoop/software/srcscp -r /software/src/zookeeper-3.4.8 hadoop@Cloud6:/home/hadoop/software/src</code></pre><p>将<code>Cloud5</code>和<code>Cloud6</code>上的<code>zookeeper/data</code>目录下<code>myid</code>文件内容进行更改，这是因为<code>zookeeper</code>集群不能重复。</p><pre><code># 在Cloud5上cd /software/src/zookeeper-3.4.8/dataecho &quot;5&quot; &gt; myid         # &gt; 符号表示写入mydi文件并覆盖原来的内容# 在Cloud6上cd /software/src/zookeeper-3.4.8/dataecho &quot;6&quot; &gt; myid</code></pre><p>配置完成之后，分别在三台服务器上启动<code>zookeeper</code></p><pre><code># 在Cloud4上cd ~cd /software/src/zookeeper-3.4.8a/./zkServer.sh start# 在Cloud5上cd ~cd /software/src/zookeeper-3.4.8/./zkServer.sh start# 在Cloud6上cd ~cd /software/src/zookeeper-3.4.8/./zkServer.sh start#分别在Cloud4，Cloud5，Cloud6上执行，下面命令查看是否启动成功。./zkServer.sh status#若其中两个是follower，一个是leader，则说明成功。</code></pre><p>将<code>zookeeper</code>添加到环境变量中</p><pre><code>cd ~vi .bashrc # 在文件最后加入jdk的环境变量export ZK_HOME=/home/hadoop/software/src/zookeeper-3.4.8         export PATH=$PATH:$ZK_HOME/bin # 同步其它两台配置文件scp ~/.bashrc hadoop@Cloud5:/home/hadoop/scp ~/.bashrc hadoop@Cloud6:/home/hadoop/</code></pre></li><li><p>安装配置<code>hadoop</code>集群<br>使用<code>hadoop</code>的这个版本<code>hadoop-2.8.2.tar.gz</code>，下载地址如下<br><a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.8.2/" target="_blank" rel="external">点击进入下载页面</a>，下载之后都样将其移动到<code>/software/app</code>这个目录下。具体安装配置如下 </p><pre><code>#解压cd /software/apptar -zxvf hadoop-2.8.2.tar.gzmv hadoop-2.8.2 ../srccd ../srccd hadoop-2.8.2/etc/hadoop  </code></pre><p><em>3.1</em> 修改<code>hadoop-env.sh</code></p><pre><code>export JAVA_HOME=/home/hadoop/software/src/jdk-8u151-linux-x64</code></pre><p><em>3.2</em> 修改<code>core-site.xml</code></p><pre><code>&lt;configuration&gt;      &lt;!-- 指定hdfs的nameservice为ns1 --&gt;      &lt;property&gt;          &lt;name&gt;fs.defaultFS&lt;/name&gt;          &lt;value&gt;hdfs://ns1&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 指定hadoop临时目录 --&gt;      &lt;property&gt;          &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;          &lt;value&gt;/home/hadoop/software/src/hadoop-2.8.2/tmp&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 指定zookeeper地址 --&gt;      &lt;property&gt;          &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;          &lt;value&gt;Cloud4:2181, Cloud5:2181, Cloud6:2181&lt;/value&gt;      &lt;/property&gt;  &lt;/configuration&gt;   </code></pre><p><em>3.3</em> 修改<code>hdfs-site.xml</code></p><pre><code>&lt;configuration&gt;      &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.nameservices&lt;/name&gt;          &lt;value&gt;ns1&lt;/value&gt;      &lt;/property&gt;      &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;          &lt;value&gt;nn1,nn2&lt;/value&gt;      &lt;/property&gt;      &lt;!-- nn1的RPC通信地址 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;          &lt;value&gt;Cloud:9000&lt;/value&gt;      &lt;/property&gt;      &lt;!-- nn1的http通信地址 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;          &lt;value&gt;Cloud:50070&lt;/value&gt;      &lt;/property&gt;      &lt;!-- nn2的RPC通信地址 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;          &lt;value&gt;Cloud2:9000&lt;/value&gt;      &lt;/property&gt;      &lt;!-- nn2的http通信地址 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;          &lt;value&gt; Cloud2:50070&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;          &lt;value&gt;qjournal://Cloud4:8485; Cloud5:8485; Cloud6:8485/ns1&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;          &lt;value&gt;/home/hadoop/software/src/hadoop-2.8.2/journal&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 开启NameNode失败自动切换 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;          &lt;value&gt;true&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 配置失败自动切换实现方式 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;      &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;      &lt;property&gt;          &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;          &lt;value&gt;          sshfence          shell(/bin/true)          &lt;/value&gt;      &lt;/property&gt;      &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;          &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 配置sshfence隔离机制超时时间 --&gt;      &lt;property&gt;          &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;          &lt;value&gt;30000&lt;/value&gt;      &lt;/property&gt;  &lt;/configuration&gt;  </code></pre><p><em>3.4</em> 修改<code>mapred-site.xml</code></p><pre><code>&lt;configuration&gt;  &lt;!-- 指定mr框架为yarn方式 --&gt;      &lt;property&gt;          &lt;name&gt;mapreduce.framework.name&lt;/name&gt;          &lt;value&gt;yarn&lt;/value&gt;      &lt;/property&gt;  &lt;/configuration&gt;  </code></pre><p><em>3.5</em> 修改<code>yarn-site.xml</code>  </p><pre><code>&lt;configuration&gt;      &lt;!-- 指定resourcemanager地址 --&gt;      &lt;property&gt;          &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;          &lt;value&gt;Cloud3&lt;/value&gt;      &lt;/property&gt;      &lt;!-- 指定nodemanager启动时加载server的方式为shuffle server --&gt;      &lt;property&gt;          &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;          &lt;value&gt;mapreduce_shuffle&lt;/value&gt;      &lt;/property&gt;  &lt;/configuration&gt;  </code></pre></li></ol><p><em>3.6</em>  创建对应的文件夹  </p><pre><code>cd hadoop-2.8.2/mkdir tmpmkdir journal</code></pre><p><em>3.7</em> 修改<code>slaves</code>文件<br><code>slaves</code>是指定子节点的位置，因为要在<code>Cloud</code>上启动<code>HDFS</code>、在<code>Cloud3</code>启动<code>yarn</code>，所以<code>Cloud</code>上的<code>slaves</code>文件指定的是<code>datanode</code>的位置，<code>Cloud3</code>上的<code>slaves</code>文件指定的是<code>nodemanager</code>的位置</p><pre><code>vi slavesCloud4Cloud5Cloud6</code></pre><p><em>3.8</em> 将配置好的<code>hadoop</code>拷贝到其它节点上</p><pre><code>    cd ~    cd /software/src/    scp -r hadoop-2.8.2/ hadoop@Cloud2:/home/hadoop/software/src    scp -r hadoop-2.8.2/ hadoop@Cloud3:/home/hadoop/software/src    scp -r hadoop-2.8.2/ hadoop@Cloud4:/home/hadoop/software/src    scp -r hadoop-2.8.2/ hadoop@Cloud5:/home/hadoop/software/src    scp -r hadoop-2.8.2/ hadoop@Cloud6:/home/hadoop/software/src*3.8* 配置环境变量    cd ~    vi .bashrc    #添加如下内容    export HADOOP_HOME=/home/hadoop/software/src/hadoop-2.8.2    export PATH=$PATH:$HADOOP_HOME/bin    #在其它五台节点上也执行同样的操作，因为前面配置zookeeper环境变量了    #所以这里不能在直接拷贝过去，需要手动在每台节点上添加环境变量</code></pre><ol><li><p>验证<code>hadoop</code>和<code>zookeeper</code>  </p><p><em>4.1</em> 启动<code>zookeeper</code><br>若之前启动的<code>zookeeper</code>进程还活着，并且正常运行，可以直接进行下面的操作，若服务不正常，可以将其关掉并重新启动。  </p><p><em>4.2</em> 启动<code>journalnode</code><br>在<code>Cloud</code>上启动所有<code>journalnode</code><font color="red">注意：</font>是调用的<code>hadoop-daemons.sh</code>这个脚本，注意是复数s的那个脚本。</p><pre><code>cd /software/src/hadoop-2.8.2sbin/hadoop-daemons.sh start journalnode#在Cloud4，Cloud5，Cloud6上运行jps命令查看是否启动#若存在JournalNode进程，即成功  </code></pre><p><em>4.3</em> 格式化<code>HDFS</code><br>在<code>Cloud</code>上执行下面命令</p><pre><code>hdfs namenode -format  </code></pre><p>格式化后会在根据<code>core-site.xml</code>中的<code>hadoop.tmp.dir</code>配置生成个文件，这里我配置的是<code>/home/hadoop/software/src/hadoop-2.8.2/tmp</code>，然后将<code>/home/hadoop/software/src/hadoop-2.8.2/tmp</code>拷贝到<code>Cloud2</code>的<code>/home/hadoop/software/src/hadoop-2.8.2/</code>下。</p><pre><code>scp -r hadoop-2.8.2/tmp/ hadoop@Cloud2:/home/hadoop/software/src/hadoop-2.8.2/</code></pre><p><em>4.4</em> 格式化<code>zookeeper</code>  </p><pre><code>hdfs zkfc -formatZK</code></pre><p><em>4.5</em> 启动<code>HDFS</code>（在<code>Cloud</code>上）  </p><pre><code>sbin/start-dfs.sh</code></pre><p><em>4.6</em> 启动<code>YARN</code><br><font color="red">注意：</font>：是在<code>Cloud3</code>上执行<code>start-yarn.sh</code>，把<code>namenode</code>和<code>resourcemanager</code>分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动。  </p><pre><code>sbin/start-yarn.sh</code></pre></li></ol><h4 id="到此hadoop集群配置完毕，可以对其测试。"><a href="#到此hadoop集群配置完毕，可以对其测试。" class="headerlink" title="到此hadoop集群配置完毕，可以对其测试。"></a>到此<code>hadoop</code>集群配置完毕，可以对其测试。</h4><ol><li><p>验证<code>hdfs HA</code>机制<br>验证上传文件成功之后，手动杀掉一个<code>namenode</code>，在查看该文件看是否存在。  </p></li><li><p>验证<code>YARN</code><br>运行一下<code>hadoop</code>提供的<code>demo</code>中的<code>WordCount</code>程序</p><pre><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /xxx /xxx</code></pre></li></ol><h2 id="Hbase集群搭建"><a href="#Hbase集群搭建" class="headerlink" title="Hbase集群搭建"></a>Hbase集群搭建</h2><ol><li><p><code>Hbase</code>使用<code>hbase-1.2.6-bin.tar.gz</code>，<a href="http://mirrors.shu.edu.cn/apache/hbase/1.2.6/" target="_blank" rel="external">下载地址传送门</a>。下载好之后，将这个文件移动到<code>/home/hadoop/software/app</code>下。在<code>windwos</code>上下载的软件，可以通过工具上传到服务器上，上传之后做下面的配置安装。安装配置如下</p><p> <em>1.2</em>　修改<code>hbase-env.sh</code>文件  </p><pre><code>cd ~ cd /software/app/tar -zxvf hbase-1.2.6-bin.tar.gzmv hbase-1.2.6 ../srccd ../src/hbase-1.2.6#修改配置文件vi hbase-env.shexport JAVA_HOME=/home/hadoop/software/src/jdk-8u151-linux-x64  # 如果jdk路径不同需要单独配置export HBASE_CLASSPATH=/home/hadoop/software/src/hadoop-2.8.2/etc/hadoop/export HBASE_MANAGES_ZK=false    # 不使用hbase自带的zk</code></pre><p> <em>1.3</em>　修改<code>hbase-site.xml</code></p><pre><code>&lt;configuration&gt;    &lt;property&gt;            &lt;name&gt;hbase.rootdir&lt;/name&gt;            &lt;value&gt;hdfs://Cloud:9000/hbase&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.master&lt;/name&gt;        &lt;value&gt;Cloud&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;            &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;            &lt;value&gt;2181&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;            &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;            &lt;value&gt;120000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;            &lt;value&gt;Cloud4,Cloud5,Cloud6&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;            &lt;name&gt;hbase.tmp.dir&lt;/name&gt;            &lt;value&gt;/home/hadoop/software/src/hbase-1.2.6/hbasedata&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;            &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;        </code></pre><p> <em>1.4</em> 创建对应的文件夹</p><pre><code>cd hbase-1.2.6/mkdir hbasedata</code></pre><p> <em>1.5</em> 修改<code>regionservers</code>文件</p><pre><code>Cloud2Cloud3</code></pre><p> <em>1.6</em> 修改环境变量   </p><pre><code>cd ~vi .bashrcexport HBASE_HOME=/hoem/hadoop/software/src/hbase-1.2.6/export PATH=$PATH:$HBASE_HOME/bin#将上面的环境变量同样在Cloud2、Cloud3上执行。</code></pre><p> <em>1.7</em> 将<code>hbase</code>拷贝到<code>Cloud2</code>，<code>Cloud3</code>节点上</p><pre><code>cd /software/srcscp -r hbase-1.2.6 hadoop@Cloud2:/home/hadoop/software/srcscp -r hbase-1.2.6 hadoop@Cloud3:/home/hadoop/software/src　　　　　　　　　</code></pre><p> <em>1.8</em> 启动<code>hbase</code><br> 在启动<code>hbase</code>之前，请确保<code>zookeeper</code>和<code>hadoop</code>都已经启动，并且正常。</p><pre><code>#在Cloud上执行cd software/src/hbase-1.2.6bin/start-hbase.sh#启动完成后，分别在Cloud、Cloud2、Cloud3上执行jps命令#Cloud上会多出一个HMaster进程#Cloud2上会多出一个HRegionServer进程#Cloud3上会多出一个HRegionServer进程</code></pre></li></ol><h2 id="Spark集群搭建"><a href="#Spark集群搭建" class="headerlink" title="Spark集群搭建"></a>Spark集群搭建</h2><ol><li><p><code>Spark</code>使用<code>spark-2.2.0-bin-hadoop2.7.tgz</code>，<a href="https://www.apache.org/dyn/closer.lua/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz" target="_blank" rel="external">下载地址传送门</a>。下载好之后，将这个文件移动到<code>/home/hadoop/software/app</code>下。在<code>windwos</code>上下载的软件，可以通过工具上传到服务器上，上传之后做下面的配置安装。</p></li><li><p>因为<code>Spark</code>需要使用<code>scala</code>，所以我们先安装<code>scala</code>。<a href="https://downloads.lightbend.com/scala/2.12.4/scala-2.12.4.tgz" target="_blank" rel="external">下载地址传送门</a>，下载之后，移动到<code>software/app/</code>目录下。</p><pre><code>cd　software/apptar -zxvf scala-2.12.4.tgztar -zxvf spark-2.2.0-bin-hadoop2.7.tgzmv scala-2.12.4 ../srcmv spark-2.2.0-bin-hadoop2.7 ../src</code></pre><p> <em>2.1</em> 配置环境变量</p><pre><code>cd ~ vi .bashrcexport SCALA_HOME=/home/hadoop/software/src/scala-2.12.4export PATH=$PATH:$SCALA_HOME/bin export SPARK_HOME=/home/hadoop/software/src/spark-2.2.0-bin-hadoop2.7export PATH=$PATH:$SPARK_HOME/bin# 将上面的环境变量在Cloud2和Cloud3上同样添加</code></pre></li><li><p>配置<code>Spark</code><br> <em>3.1</em> 修改<code>spark-env.sh</code></p><pre><code>cd software/src/spark-2.2.0-bin-hadoop2.7/confcp spark-env.sh.template spark-env.sh # 在末尾加入vi spark-env.shexport JAVA_HOME=/home/hadoop/software/src/jdk-8u151-linux-x64export SCALA_HOME=/home/hadoop/bigdata/src/scala-2.12.4export SPARK_WORKER_MEMORY=2gexport SPARK_MASTER_IP=192.168.1.100 #Master对应的ipexport HADOOP_CONF_DIR=/home/hadoop/software/src/hadoop-2.8.2export SPARK_JAR=/home/hadoop/software/src/spark-2.2.0-bin-hadoop2.7/jars</code></pre><p> <em>3.2</em> 修改<code>slaves</code>文件</p><pre><code>cd software/src/spark-2.2.0-bin-hadoop2.7/confcp slaves.template slaves # 添加work节点vi slavesCloud2Cloud3</code></pre><p> <em>3.3</em>    <code>spark</code>集群复制  </p><pre><code>cd ~cd software/src/scp -r scala-2.12.4/ hadoop@Cloud2:/home/hadoop/software/src/scp -r scala-2.12.4/ hadoop@Cloud3:/home/hadoop/software/src/scp -r spark-2.2.0-bin-hadoop2.7/ hadoop@Cloud2:/home/hadoop/software/src/scp -r spark-2.2.0-bin-hadoop2.7/ hadoop@Cloud2:/home/hadoop/software/src/</code></pre><p> <em>3.4</em> <code>spark</code>集群启动</p><pre><code>cd software/src/spark-2.2.0-bin-hadoop2.7sbin/start-all.sh#在Cloud、Cloud2、Cloud3上使用jps命令查看是否配置成功#Cloud上会多出一个Master进程#Cloud2和Cloud3上会多出一个Worker进程</code></pre></li></ol><h2 id="hive集群搭建"><a href="#hive集群搭建" class="headerlink" title="hive集群搭建"></a>hive集群搭建</h2><ol><li><p><code>Hive</code>使用<code>apache-hive-2.2.0-bin.tar.gz</code>，<a href="http://mirrors.hust.edu.cn/apache/hive/hive-2.2.0/" target="_blank" rel="external">下载地址传送门</a>。下载好之后，将这个文件移动到<code>/home/hadoop/software/app</code>下。具体配置如下</p><pre><code>cd ~cd software/apptar -zxvf apache-hive-2.2.0-bin.tar.gzmv apache-hive-2.2.0-bin ../src#配置环境变量cd ~vi .bashrcexport HIVE_HOME=/home/hadoop/software/src/apache-hive-2.2.0-binexport PATH=$PATH:$HIVE_HOME/bin#最后source .bashrc</code></pre></li><li><p>对<code>hive</code>进行配置  </p><pre><code>cd ~cd software/src/apache-hive-2.2.0-bin/confcp hive-env.sh.template hive-env.sh#加入以下内容vi hive-env.shexport JAVA_HOME=/home/hadoop/software/src/jdk-8u151-linux-x64export HADOOP_HOME=/home/hadoop/software/src/hadoop-2.8.2export HIVE_HOME=/home/hadoop/bigdata/src/apache-hive-2.2.0-binexport HIVE_CONF_DIR=/home/hadoop/bigdata/src/apache-hive-2.2.0-bin/conf</code></pre></li><li><p>修改<code>hbase-site.xml</code>文件</p><pre><code>cd software/src/apache-hive-2.2.0-bin/conftouch hive-site.xmlvi hive-site.xml&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;        &lt;value&gt;jdbc:mysql://hive:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;    &lt;/property&gt;       &lt;property&gt;         &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;         &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;          &lt;/property&gt;                   &lt;property&gt;         &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;        &lt;value&gt;hive&lt;value&gt;    &lt;/property&gt;    &lt;property&gt;          &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;        &lt;value&gt;hive&lt;/value&gt;    &lt;/property&gt;          &lt;/configuration&gt;</code></pre></li><li><p><code>jdbc</code>驱动下载</p><pre><code>wget http://cdn.mysql.com/Downloads/Connector-J/mysql-connector-java-5.1.36.tar.gzcp mysql-connector-java-5.1.33-bin.jar apache-hive-2.2.0-bin/lib/</code></pre></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据项目需求我们搭建了一套&lt;code&gt;Hadoop&lt;/code&gt; + &lt;code&gt;Spark&lt;/code&gt; + &lt;code&gt;Hbase&lt;/code&gt; + &lt;code&gt;Hive&lt;/code&gt;的架构方案。目前服务器总共有六台，每台服务器有五块硬盘，大小分别是&lt;code&gt;300G&lt;/code&gt;、&lt;code&gt;300G&lt;/code&gt;、&lt;code&gt;4T&lt;/code&gt;、&lt;code&gt;4T&lt;/code&gt;、&lt;code&gt;4T&lt;/code&gt;，各个服务器主机名分别为&lt;code&gt;Cloud&lt;/code&gt;、&lt;code&gt;Cloud2&lt;/code&gt;、&lt;code&gt;Cloud3&lt;/code&gt;、&lt;code&gt;Cloud4&lt;/code&gt;、&lt;code&gt;Cloud5&lt;/code&gt;、&lt;code&gt;Cloud6&lt;/code&gt;。具体使用情况分别如下表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Cloud&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;Cloud2&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;Cloud3&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;Cloud4&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;Cloud5&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;Cloud6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;300G&lt;/code&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;系统&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;系统&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;系统&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;系统&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;系统&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;系统&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;300G&lt;/code&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;软件&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;软件&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;软件&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;软件&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;软件&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;软件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;4T&lt;/code&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;4T&lt;/code&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;存储数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;4T&lt;/code&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;备份&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;备份&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;备份&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;备份&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;备份&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;备份&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;每台服务器都是&lt;code&gt;centos7&lt;/code&gt;的系统，配置完全相同。项目架构所需要安装的软件和各个服务器上所运行的服务具体情况如下表，由于学校不能申请过多的临时&lt;code&gt;IP&lt;/code&gt;地址，所以这里先使用内网地址配置，后期会更改为正式&lt;code&gt;IP&lt;/code&gt;。&lt;br&gt;
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://hanwen.me/tags/Hadoop/"/>
    
      <category term="Hbase" scheme="http://hanwen.me/tags/Hbase/"/>
    
      <category term="Spark" scheme="http://hanwen.me/tags/Spark/"/>
    
      <category term="Hive" scheme="http://hanwen.me/tags/Hive/"/>
    
      <category term="Mysql" scheme="http://hanwen.me/tags/Mysql/"/>
    
      <category term="集群" scheme="http://hanwen.me/tags/%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>omnet++安装和使用</title>
    <link href="http://hanwen.me/2017/12/25/omnet-install-and-use/"/>
    <id>http://hanwen.me/2017/12/25/omnet-install-and-use/</id>
    <published>2017-12-25T09:52:57.000Z</published>
    <updated>2018-01-04T14:34:03.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>登录<code>OMNeT++</code>官网下载对应的<code>windos</code>版本, 官网地址<a href="https://www.omnetpp.org/omnetpp" target="_blank" rel="external">点击这里</a>点击对应的连接进行下在 </p></blockquote><p><img src="../images/omnet1.jpg" alt="Alt text"><br><a id="more"></a></p><blockquote><p>下载之后，用压缩文件进行解压到本地文件下，进入<code>omnet++</code>根目录，找到下面这个文件  </p></blockquote><p><img src="../images/omnet6.jpg" alt="Alt text"></p><blockquote><p>双击上面的文件，进入到<code>shell</code>环境下面  </p></blockquote><p><img src="../images/omnet7.jpg" alt="Alt text"></p><blockquote><p>在命令行中输入<code>./configure</code>  </p></blockquote><p><img src="../images/omnet8.jpg" alt="Alt text"></p><blockquote><p>第五步完成之后继续输入<code>make</code>,这个过程有点长，需要耐心一段时间。  </p></blockquote><p><img src="../images/omnet9.jpg" alt="Alt text"></p><blockquote><p>第六步完成之后会出现下面这样的结果  </p></blockquote><p><img src="../images/omnet2.jpg" alt="Alt text"></p><blockquote><p>接下来我们根据提示输入对应的命令，启动我们的编译环境  </p></blockquote><p><img src="../images/omnet3.jpg" alt="Alt text"></p><blockquote><p>启动之后，会提示你选择一个工作目录，这里用默认的目录就可以  </p></blockquote><p><img src="../images/omnet4.jpg" alt="Alt text"></p><blockquote><p>之后就会进入环境的主页面，如下  </p></blockquote><p><img src="../images/omnet5.jpg" alt="Alt text"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;登录&lt;code&gt;OMNeT++&lt;/code&gt;官网下载对应的&lt;code&gt;windos&lt;/code&gt;版本, 官网地址&lt;a href=&quot;https://www.omnetpp.org/omnetpp&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;点击这里&lt;/a&gt;点击对应的连接进行下在 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;../images/omnet1.jpg&quot; alt=&quot;Alt text&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="OMNeT++" scheme="http://hanwen.me/tags/OMNeT/"/>
    
  </entry>
  
  <entry>
    <title>REST-Webservice和SOAP-Webservice的比较</title>
    <link href="http://hanwen.me/2017/12/23/rest-webservice-and-soap-webservice/"/>
    <id>http://hanwen.me/2017/12/23/rest-webservice-and-soap-webservice/</id>
    <published>2017-12-23T14:16:44.000Z</published>
    <updated>2017-12-23T14:40:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>　　在<code>SOA</code>的基础技术实现方式中<code>WebService</code>占据了很重要的地位，通常我们提到<code>WebService</code>第一想法就是<code>SOAP</code>消息在各种传输协议上交互。近几年<code>REST</code>的思想伴随着<code>SOA</code>逐渐被大家接受，同时各大网站不断开放<code>API</code>提供给开发者，也激起了<code>REST</code>风格<code>WebService</code>的热潮。  </p><p>　　什么是<code>SOAP</code>，我想不用多说，google一把满眼都是。其实<code>SOAP</code>最早是针对<code>RPC</code>的一种解决方案，简单对象访问协议，很轻量，同时作为应用协议可以基于多种传输协议来传递消息<code>（Http,SMTP等）</code>。但是随着<code>SOAP</code>作为<code>WebService</code>的广泛应用，不断地增加附加的内容，使得现在开发人员觉得<code>SOAP</code>很重，使用门槛很高。在<code>SOAP</code>后续的发展过程中，<code>WS-*</code>系列协议的制定，增加了<code>SOAP</code>的成熟度，也给<code>SOAP</code>增加了负担。</p><h2 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h2><p>　　<code>REST</code>其实并不是什么协议也不是什么标准，而是将<code>Http</code>协议的设计初衷作了诠释，在<code>Http</code>协议被广泛利用的今天，越来越多的是将其作为传输协议，而非原先设计者所考虑的应用协议。<code>SOAP</code>类型的<code>WebService</code>就是最好的例子，<code>SOAP</code>消息完全就是将<code>Http</code>协议作为消息承载，以至于对于<code>Http</code>协议中的各种参数（例如编码，错误码等）都置之不顾。其实，最轻量级的应用协议就是<code>Http</code>协议。<code>Http</code>协议所抽象的<code>get</code>,<code>post</code>,<code>put</code>,<code>delete</code>就好比数据库中最基本的增删改查，而互联网上的各种资源就好比数据库中的记录（可能这么比喻不是很好），对于各种资源的操作最后总是能抽象成为这四种基本操作，在定义了定位资源的规则以后，对于资源的操作通过标准的<code>Http</code>协议就可以实现，开发者也会受益于这种轻量级的协议。</p><a id="more"></a><h2 id="REST的思想归结以下有如下几个关键点"><a href="#REST的思想归结以下有如下几个关键点" class="headerlink" title="REST的思想归结以下有如下几个关键点"></a>REST的思想归结以下有如下几个关键点</h2><ol><li><p>面向资源的接口设计<br>所有的接口设计都是针对资源来设计的，也就很类似于我们的面向对象和面向过程的设计区别，只不过现在将网络上的操作实体都作为资源来看待，同时<code>URI</code>的设计也是体现了对于资源的定位设计。后面会提到有一些网站的<code>API</code>设计说是<code>REST</code>设计，其实是<code>RPC-REST</code>的混合体，并非是<code>REST</code>的思想。</p></li><li><p>抽象操作为基础的<code>CRUD</code><br>这点很简单，<code>Http</code>中的<code>get</code>,<code>put</code>,<code>post</code>,<code>delete</code>分别对应了<code>read</code>,<code>update</code>,<code>create</code>,<code>delete</code>四种操作，如果仅仅是作为对于资源的操作，抽象成为这四种已经足够了，但是对于现在的一些复杂的业务服务接口设计，可能这样的抽象未必能够满足。其实这也在后面的几个网站的<code>API</code>设计中暴露了这样的问题，如果要完全按照<code>REST</code>的思想来设计，那么适用的环境将会有限制，而非放之四海皆准的。      </p></li><li><p><code>Http</code>是应用协议而非传输协议<br>这点在后面各大网站的<code>API</code>分析中有很明显的体现，其实有些网站已经走到了<code>SOAP</code>的老路上，说是<code>REST</code>的理念设计，其实是作了一套私有的<code>SOAP</code>协议，因此称之为REST风格的自定义<code>SOAP</code>协议。</p></li><li><p>无状态，自包含<br>这点其实不仅仅是对于<code>REST</code>来说的，作为接口设计都需要能够做到这点，也是作为可扩展和高效性的最基本的保证，就算是使用<code>SOAP</code>的<code>WebService</code>也是一样。</p></li></ol><h2 id="REST-vs-SOAP"><a href="#REST-vs-SOAP" class="headerlink" title="REST vs SOAP"></a>REST vs SOAP</h2><h4 id="成熟度"><a href="#成熟度" class="headerlink" title="成熟度"></a>成熟度</h4><p>　　<code>SOAP</code>虽然发展到现在已经脱离了初衷，但是对于异构环境服务发布和调用，以及厂商的支持都已经达到了较为成熟的情况。不同平台，开发语言之间通过<code>SOAP</code>来交互的<code>web service</code>都能够较好的互通（在部分复杂和特殊的参数和返回对象解析上，协议没有作很细致的规定，导致还是需要作部分修正）</p><p>　　<code>REST</code>国外很多大网站都发布了自己的开发<code>API</code>，很多都提供了<code>SOAP</code>和<code>REST</code>两种<code>Web Service</code>，根据调查部分网站的<code>REST</code>风格的使用情况要高于<code>SOAP</code>。但是由于<code>REST</code>只是一种基于<code>Http</code>协议实现资源操作的思想，因此各个网站的<code>REST</code>实现都自有一套，在后面会讲诉各个大网站的<code>REST API</code>的风格。也正是因为这种各自实现的情况，在性能和可用性上会大大高于<code>SOAP</code>发布的<code>web service</code>，但统一通用方面远远不及<code>SOAP</code>。由于这些大网站的<code>SP</code>往往专注于此网站的<code>API</code>开发，因此通用性要求不高。</p><p>　　由于没有类似于<code>SOAP</code>的权威性协议作为规范，<code>REST</code>实现的各种协议仅仅只能算是私有协议，当然需要遵循<code>REST</code>的思想，但是这样细节方面有太多没有约束的地方。REST日后的发展所走向规范也会直接影响到这部分的设计是否能够有很好的生命力。</p><p>　　总的来说<code>SOAP</code>在成熟度上优于<code>REST</code>。</p><h4 id="效率和易用性："><a href="#效率和易用性：" class="headerlink" title="效率和易用性："></a>效率和易用性：</h4><p>　　<code>SOAP</code>协议对于消息体和消息头都有定义，同时消息头的可扩展性为各种互联网的标准提供了扩展的基础，<code>WS-*</code>系列就是较为成功的规范。但是也由于<code>SOAP</code>由于各种需求不断扩充其本身协议的内容，导致在<code>SOAP</code>处理方面的性能有所下降。同时在易用性方面以及学习成本上也有所增加。</p><p>　　<code>REST</code>被人们的重视，其实很大一方面也是因为其高效以及简洁易用的特性。这种高效一方面源于其面向资源接口设计以及操作抽象简化了开发者的不良设计，同时也最大限度的利用了<code>Http</code>最初的应用协议设计理念。同时，在我看来<code>REST</code>还有一个很吸引开发者的就是能够很好的融合当前<code>Web2.0</code>的很多前端技术来提高开发效率。例如很多大型网站开放的<code>REST</code>风格的<code>API</code>都会有多种返回形式，除了传统的<code>xml</code>作为数据承载，还有<code>（JSON,RSS,ATOM）</code>等形式，这对很多网站前端开发人员来说就能够很好的<code>mashup</code>各种资源信息。</p><p>　　因此在效率和易用性上来说，<code>REST</code>更胜一筹。</p><h4 id="安全性："><a href="#安全性：" class="headerlink" title="安全性："></a>安全性：</h4><p>　　这点其实可以放入到成熟度中，不过在当前的互联网应用和平台开发设计过程中，安全已经被提到了很高的高度，特别是作为外部接口给第三方调用，安全性可能会高过业务逻辑本身。</p><p>　　<code>SOAP</code>在安全方面是通过使用<code>XML-Security</code>和<code>XML-Signature</code>两个规范组成了<code>WS-Security</code>来实现安全控制的，当前已经得到了各个厂商的支持，<code>.net</code>，<code>php</code> ，<code>java</code> 都已经对其有了很好的支持（虽然在一些细节上还是有不兼容的问题，但是互通基本上是可以的）。</p><p>　　<code>REST</code>没有任何规范对于安全方面作说明，同时现在开放<code>REST</code>风格<code>API</code>的网站主要分成两种，一种是自定义了安全信息封装在消息中（其实这和<code>SOAP</code>没有什么区别），另外一种就是靠硬件<code>SSL</code>来保障,但是这只能够保证点到点的安全，如果是需要多点传输的话<code>SSL</code>就无能为力了。</p><h4 id="应用设计与改造："><a href="#应用设计与改造：" class="headerlink" title="应用设计与改造："></a>应用设计与改造：</h4><p>　　我们的系统要么就是已经有了那些需要被发布出去的服务，要么就是刚刚设计好的服务，但是开发人员的传统设计思想让<code>REST</code>的形式被接受还需要一点时间。同时在资源型数据服务接口设计上来说按照<code>REST</code>的思想来设计相对来说要容易一些，而对于一些复杂的服务接口来说，可能强要去按照<code>REST</code>的风格来设计会有些牵强。这一点其实可以看看各大网站的接口就可以知道，很多网站还要传入<code>function</code>的名称作为参数，这就明显已经违背了<code>REST</code>本身的设计思路。而<code>SOAP</code>本身就是面向<code>RPC</code>来设计的，开发人员十分容易接受，所以不存在什么适应的过程。</p><p>　　总的来说，其实还是一个老观念，适合的才是最好的</p><p>　　技术没有好坏，只有是不是合适，一种好的技术和思想被误用了，那么就会得到反效果。<code>REST</code>和<code>SOAP</code>各自都有自己的优点，同时如果在一些场景下如果去改造<code>REST</code>，其实就会走向<code>SOAP</code>（例如安全）。</p><p>　　<code>REST</code>对于资源型服务接口来说很合适，同时特别适合对于效率要求很高，但是对于安全要求不高的场景。而<code>SOAP</code>的成熟性可以给需要提供给多开发语言的，对于安全性要求较高的接口设计带来便利。所以我觉得纯粹说什么设计模式将会占据主导地位没有什么意义，关键还是看应用场景。</p><p>　　同时很重要一点就是不要扭曲了<code>REST</code>现在很多网站都跟风去开发<code>REST</code>风格的接口，其实都是在学其形，不知其心，最后弄得不伦不类，性能上不去，安全又保证不了，徒有一个看似象摸象样的皮囊。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　在&lt;code&gt;SOA&lt;/code&gt;的基础技术实现方式中&lt;code&gt;WebService&lt;/code&gt;占据了很重要的地位，通常我们提到&lt;code&gt;WebService&lt;/code&gt;第一想法就是&lt;code&gt;SOAP&lt;/code&gt;消息在各种传输协议上交互。近几年&lt;code&gt;REST&lt;/code&gt;的思想伴随着&lt;code&gt;SOA&lt;/code&gt;逐渐被大家接受，同时各大网站不断开放&lt;code&gt;API&lt;/code&gt;提供给开发者，也激起了&lt;code&gt;REST&lt;/code&gt;风格&lt;code&gt;WebService&lt;/code&gt;的热潮。  &lt;/p&gt;
&lt;p&gt;　　什么是&lt;code&gt;SOAP&lt;/code&gt;，我想不用多说，google一把满眼都是。其实&lt;code&gt;SOAP&lt;/code&gt;最早是针对&lt;code&gt;RPC&lt;/code&gt;的一种解决方案，简单对象访问协议，很轻量，同时作为应用协议可以基于多种传输协议来传递消息&lt;code&gt;（Http,SMTP等）&lt;/code&gt;。但是随着&lt;code&gt;SOAP&lt;/code&gt;作为&lt;code&gt;WebService&lt;/code&gt;的广泛应用，不断地增加附加的内容，使得现在开发人员觉得&lt;code&gt;SOAP&lt;/code&gt;很重，使用门槛很高。在&lt;code&gt;SOAP&lt;/code&gt;后续的发展过程中，&lt;code&gt;WS-*&lt;/code&gt;系列协议的制定，增加了&lt;code&gt;SOAP&lt;/code&gt;的成熟度，也给&lt;code&gt;SOAP&lt;/code&gt;增加了负担。&lt;/p&gt;
&lt;h2 id=&quot;REST&quot;&gt;&lt;a href=&quot;#REST&quot; class=&quot;headerlink&quot; title=&quot;REST&quot;&gt;&lt;/a&gt;REST&lt;/h2&gt;&lt;p&gt;　　&lt;code&gt;REST&lt;/code&gt;其实并不是什么协议也不是什么标准，而是将&lt;code&gt;Http&lt;/code&gt;协议的设计初衷作了诠释，在&lt;code&gt;Http&lt;/code&gt;协议被广泛利用的今天，越来越多的是将其作为传输协议，而非原先设计者所考虑的应用协议。&lt;code&gt;SOAP&lt;/code&gt;类型的&lt;code&gt;WebService&lt;/code&gt;就是最好的例子，&lt;code&gt;SOAP&lt;/code&gt;消息完全就是将&lt;code&gt;Http&lt;/code&gt;协议作为消息承载，以至于对于&lt;code&gt;Http&lt;/code&gt;协议中的各种参数（例如编码，错误码等）都置之不顾。其实，最轻量级的应用协议就是&lt;code&gt;Http&lt;/code&gt;协议。&lt;code&gt;Http&lt;/code&gt;协议所抽象的&lt;code&gt;get&lt;/code&gt;,&lt;code&gt;post&lt;/code&gt;,&lt;code&gt;put&lt;/code&gt;,&lt;code&gt;delete&lt;/code&gt;就好比数据库中最基本的增删改查，而互联网上的各种资源就好比数据库中的记录（可能这么比喻不是很好），对于各种资源的操作最后总是能抽象成为这四种基本操作，在定义了定位资源的规则以后，对于资源的操作通过标准的&lt;code&gt;Http&lt;/code&gt;协议就可以实现，开发者也会受益于这种轻量级的协议。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Restful" scheme="http://hanwen.me/tags/Restful/"/>
    
      <category term="SOAP" scheme="http://hanwen.me/tags/SOAP/"/>
    
  </entry>
  
  <entry>
    <title>Linux下安装Tomcat</title>
    <link href="http://hanwen.me/2017/12/22/install-tomcat/"/>
    <id>http://hanwen.me/2017/12/22/install-tomcat/</id>
    <published>2017-12-22T14:38:15.000Z</published>
    <updated>2018-01-07T14:43:13.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>Tomcat</code>官网 <a href="http://tomcat.apache.org" target="_blank" rel="external">点击这里</a></p><pre><code>cd /usr/local/src/wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gztar -zxvf apache-tomcat-8.5.24.tar.gzmv apache-tomcat-8.5.24.tar.gz /usr/local/tomcatcp -p /usr/local/tomcat/bin/catalina.sh /etc/init.d/tomcatvim /etc/init.d/tomcat //第二行加入# chkconfig: 112 63 37# description: tomcat server init script# Source Function Library. /etc/init.d/functionsJAVA_HOME=/usr/local/jdk1.8.0_23/CATALINA_HOME=/usr/local/tomcat</code></pre><a id="more"></a><pre><code>chmod 755 /etc/init.d/tomcatchkconfig --add tomcatchkconfig tomcat onservice tomcat startps aux |grep tomcat</code></pre><p>浏览器输入<a href="http://[自己的ip]:8080" target="_blank" rel="external">http://[自己的ip]:8080</a> 可以看到tomcat的欢迎页</p><p>更改默认启动端口，</p><pre><code>vim conf/server.xmlConnector port=&quot;8080&quot; 改为Connector port=&quot;80&quot;</code></pre><p>配置新虚拟主机：找到<code>&lt;/Host&gt;</code>下一行插入新的<code>&lt;Host&gt;</code>内容如下：</p><pre><code>&lt;Host name=&quot;www.123.cn&quot; appBase=&quot;/data/tomcatweb&quot;    unpackWARs=&quot;false&quot; autoDeploy=&quot;true&quot;    xmlValidation=&quot;false&quot; xmlNamespaceAware=&quot;false&quot;&gt;    &lt;Context path=&quot;&quot; docBase=&quot;./&quot; debug=&quot;0&quot; reloadable=&quot;true&quot; crossContext=&quot;true&quot;/&gt;&lt;/Host&gt;</code></pre><p>重启</p><pre><code>service tomcat stop;service tomcat start</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Tomcat&lt;/code&gt;官网 &lt;a href=&quot;http://tomcat.apache.org&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;点击这里&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /usr/local/src/

wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.24/bin/apache-tomcat-8.5.24.tar.gz

tar -zxvf apache-tomcat-8.5.24.tar.gz

mv apache-tomcat-8.5.24.tar.gz /usr/local/tomcat

cp -p /usr/local/tomcat/bin/catalina.sh /etc/init.d/tomcat

vim /etc/init.d/tomcat //第二行加入
# chkconfig: 112 63 37
# description: tomcat server init script
# Source Function Library
. /etc/init.d/functions
JAVA_HOME=/usr/local/jdk1.8.0_23/
CATALINA_HOME=/usr/local/tomcat
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://hanwen.me/tags/Linux/"/>
    
      <category term="Tomcat" scheme="http://hanwen.me/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>pig使用笔记</title>
    <link href="http://hanwen.me/2017/12/19/pig-use/"/>
    <id>http://hanwen.me/2017/12/19/pig-use/</id>
    <published>2017-12-19T15:32:41.000Z</published>
    <updated>2017-12-19T15:36:35.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-安装Pig"><a href="#1-安装Pig" class="headerlink" title="1. 安装Pig"></a>1. 安装Pig</h3><blockquote><p>   将pig添加到环境变量当中</p></blockquote><h3 id="2-pig使用"><a href="#2-pig使用" class="headerlink" title="2. pig使用"></a>2. pig使用</h3><blockquote><p>   首先将数据库中的数据导入到HDFS上</p></blockquote><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/yun --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td&apos;sqoop import --connect jdbc:mysql://192.168.1.10:3306/yun --username root --password 123  --table user_info --target-dir &apos;/sqoop/ui&apos;</code></pre><a id="more"></a><blockquote><p>td = load ‘/sqoop/td’ using PigStorage(‘,’) as (id:long, account:chararray, income:double, expenses:double, time:chararray);<br>ui = load ‘/sqoop/ui’ using PigStorage(‘,’) as (id:long, account:chararray, name:chararray, age:int);</p></blockquote><pre><code>td1 = foreach td generate account, income, expenses, income-expenses as surplus;td2 = group td1 by account;td3 = foreach td2 generate group as account, SUM(td1.income) as income, SUM(td1.expenses) as expenses, SUM(td1.surplus) as surplus;tu = join td3 by account, ui by account;result = foreach tu generate td3::account as account, ui::name, td3::income, td3::expenses, td3::surplus;store result into &apos;/result&apos; using PigStorage(&apos;,&apos;);</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-安装Pig&quot;&gt;&lt;a href=&quot;#1-安装Pig&quot; class=&quot;headerlink&quot; title=&quot;1. 安装Pig&quot;&gt;&lt;/a&gt;1. 安装Pig&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;   将pig添加到环境变量当中&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;2-pig使用&quot;&gt;&lt;a href=&quot;#2-pig使用&quot; class=&quot;headerlink&quot; title=&quot;2. pig使用&quot;&gt;&lt;/a&gt;2. pig使用&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;   首先将数据库中的数据导入到HDFS上&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;sqoop import --connect jdbc:mysql://192.168.1.10:3306/yun --username root --password 123  --table trade_detail --target-dir &amp;apos;/sqoop/td&amp;apos;
sqoop import --connect jdbc:mysql://192.168.1.10:3306/yun --username root --password 123  --table user_info --target-dir &amp;apos;/sqoop/ui&amp;apos;
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://hanwen.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Pig" scheme="http://hanwen.me/tags/Pig/"/>
    
  </entry>
  
</feed>
